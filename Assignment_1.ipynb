{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNNlw7Z-S965"
      },
      "source": [
        "#Assignment 1: Build FeedForward Neural Network Architecture \n",
        "\n",
        "The goal of this assignment is twofold: (i) implement and use gradient descent (and its variants) with\n",
        "backpropagation for a classification task (ii) get familiar with wandb which is a cool tool for running and keeping track of a large number of experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4QoUJr0THu3"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:04.785354Z",
          "iopub.status.busy": "2023-03-17T18:35:04.784944Z",
          "iopub.status.idle": "2023-03-17T18:35:17.158638Z",
          "shell.execute_reply": "2023-03-17T18:35:17.157173Z",
          "shell.execute_reply.started": "2023-03-17T18:35:04.785317Z"
        },
        "id": "_V3jTIQpTOyS",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-90fc07b79712>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from sklearn import metrics\n",
        "import random\n",
        "from keras.datasets import mnist\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.colors\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import log_loss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        " \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6_p5F27TRDy"
      },
      "source": [
        "### Installing and Login to Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:17.160988Z",
          "iopub.status.busy": "2023-03-17T18:35:17.160266Z",
          "iopub.status.idle": "2023-03-17T18:35:33.434003Z",
          "shell.execute_reply": "2023-03-17T18:35:33.432440Z",
          "shell.execute_reply.started": "2023-03-17T18:35:17.160948Z"
        },
        "id": "kE3b2hyRN6tC",
        "outputId": "70010c2a-52ac-4c86-a5e3-cdf9c53888a2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m035\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login(key = \"13ebf1b4a6b39617b6456bf8f57f55bb361759b2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:33.436253Z",
          "iopub.status.busy": "2023-03-17T18:35:33.435850Z",
          "iopub.status.idle": "2023-03-17T18:35:36.038963Z",
          "shell.execute_reply": "2023-03-17T18:35:36.037561Z",
          "shell.execute_reply.started": "2023-03-17T18:35:33.436213Z"
        },
        "id": "ayQLhGJoAwQv",
        "outputId": "0ee182ae-ee36-4f5a-9ddb-4904b865a4df",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "labels = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.043205Z",
          "iopub.status.busy": "2023-03-17T18:35:36.042812Z",
          "iopub.status.idle": "2023-03-17T18:35:36.052577Z",
          "shell.execute_reply": "2023-03-17T18:35:36.050961Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.043161Z"
        },
        "id": "-uSN_ZDMAw_q",
        "outputId": "3b7c90bb-b832-4a22-a282-d4d53bec30c6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "60000\n",
            "60000\n",
            "[9 0 0 ... 3 0 5]\n"
          ]
        }
      ],
      "source": [
        "# checking details of dataset\n",
        "print(train_images.shape)\n",
        "print(len(train_images))\n",
        "print(len(train_labels))\n",
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.055016Z",
          "iopub.status.busy": "2023-03-17T18:35:36.054547Z",
          "iopub.status.idle": "2023-03-17T18:35:36.064180Z",
          "shell.execute_reply": "2023-03-17T18:35:36.062605Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.054966Z"
        },
        "id": "x6h8FtxYBAAB",
        "outputId": "f09ad264-144d-4066-cbdc-fe537654eae6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60000 28 28\n"
          ]
        }
      ],
      "source": [
        "N , a , b = train_images.shape\n",
        "#Dimesion of each Datapoint will be a*b\n",
        "print(N,a,b)\n",
        "x = a*b\n",
        "d = x\n",
        "nl = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.067459Z",
          "iopub.status.busy": "2023-03-17T18:35:36.066735Z",
          "iopub.status.idle": "2023-03-17T18:35:36.770922Z",
          "shell.execute_reply": "2023-03-17T18:35:36.769540Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.067337Z"
        },
        "id": "pNmFx17BbCY9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "c = list(zip(train_images, train_labels))\n",
        "random.shuffle(c)\n",
        "\n",
        "labels = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "N , a , b = train_images.shape\n",
        "\n",
        "train_images, train_labels = zip(*c)\n",
        "train_images = np.array(train_images) \n",
        "train_labels = np.array(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.773667Z",
          "iopub.status.busy": "2023-03-17T18:35:36.773164Z",
          "iopub.status.idle": "2023-03-17T18:35:36.779889Z",
          "shell.execute_reply": "2023-03-17T18:35:36.778716Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.773616Z"
        },
        "id": "_uzxa_ShHd7U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# wandb.init(project=\"Assignment 1\",name=\"Question 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l39O5G0LLouw"
      },
      "source": [
        "#Question 1\n",
        "Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid below. Use from keras.datasets import fashion_mnist for getting the fashion mnist dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.782740Z",
          "iopub.status.busy": "2023-03-17T18:35:36.782291Z",
          "iopub.status.idle": "2023-03-17T18:35:36.792670Z",
          "shell.execute_reply": "2023-03-17T18:35:36.791132Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.782698Z"
        },
        "id": "1DDfpoyEVbND",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def show_images(train_images , train_labels , desc):\n",
        "  \n",
        "    fig, axs = plt.subplots(2, 5, figsize=(12, 6))\n",
        "    axs = axs.flatten()\n",
        "    class_images=[]\n",
        "\n",
        "    for i in range(10):\n",
        "          index=np.argmax(train_labels==i)\n",
        "          # Plot the image\n",
        "          axs[i].imshow(train_images[index], cmap='gray')\n",
        "          axs[i].set_title(labels[i])\n",
        "          axs[i].axis('off')\n",
        "          image = wandb.Image(train_images[index], caption=labels[i])\n",
        "          class_images.append(image)\n",
        "\n",
        "    wandb.log({\"examples\": class_images})\n",
        "    \n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIDREPHNHRWh"
      },
      "source": [
        "# Question 2 (10 Marks)\n",
        "Implement a feedforward neural network which takes images from the fashion-mnist data as input and outputs a probability distribution over the 10 classes.\n",
        "\n",
        "Your code should be flexible such that it is easy to change the number of hidden layers and the number of neurons in each hidden layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkCkYjcLLusM"
      },
      "source": [
        "###Propecessing of data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.794640Z",
          "iopub.status.busy": "2023-03-17T18:35:36.794264Z",
          "iopub.status.idle": "2023-03-17T18:35:37.008394Z",
          "shell.execute_reply": "2023-03-17T18:35:37.006996Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.794606Z"
        },
        "id": "zJ2nvR4fdIdz",
        "outputId": "fe10c1d9-e594-4b44-e278-3e8bbacae58c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "Shape of flattened_train_images is :  (60000, 784)\n",
            "Shape of flattened_test_images is  :  (10000, 784)\n"
          ]
        }
      ],
      "source": [
        "#Flattening we are converting the 28*28 data point as 784*1 data point\n",
        "print(train_images.shape)\n",
        "\n",
        "flattened_images = []\n",
        "for i in range(len(train_images)):\n",
        "    flattened_image = train_images[i].flatten()\n",
        "    flattened_images.append(flattened_image)\n",
        "flatted_train_images = np.array(flattened_images)\n",
        "\n",
        "print(\"Shape of flattened_train_images is : \",flatted_train_images.shape)\n",
        "\n",
        "  \n",
        "#Same transition for testdata\n",
        "flattened_images = []\n",
        "for i in range(len(test_images)):\n",
        "    flattened_image = test_images[i].flatten()\n",
        "    flattened_images.append(flattened_image)\n",
        "flatted_test_images = np.array(flattened_images)\n",
        "print(\"Shape of flattened_test_images is  : \",flatted_test_images.shape)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.009879Z",
          "iopub.status.busy": "2023-03-17T18:35:37.009543Z",
          "iopub.status.idle": "2023-03-17T18:35:37.071251Z",
          "shell.execute_reply": "2023-03-17T18:35:37.069593Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.009847Z"
        },
        "id": "uC7nrfY8WEWB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#getting train data and validation data from training data\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, valid_x, cat_train_y, cat_val_y = train_test_split(flatted_train_images, train_labels, test_size=0.1, stratify = train_labels ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.073426Z",
          "iopub.status.busy": "2023-03-17T18:35:37.072929Z",
          "iopub.status.idle": "2023-03-17T18:35:37.114751Z",
          "shell.execute_reply": "2023-03-17T18:35:37.113505Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.073387Z"
        },
        "id": "tOnDidLOiujh",
        "outputId": "e40c4339-614f-4588-b8b8-e94bbc724c54",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(54000, 10)\n",
            "(6000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "source": [
        "#One hot encoding of categorical labels \n",
        "def encode(data, nl):\n",
        "    encode_data = np.zeros((len(data), nl))\n",
        "    for i in range(len(data)):\n",
        "        actual_label = data[i]\n",
        "        encode_data[i][actual_label] = 1\n",
        "    return encode_data\n",
        "\n",
        "\n",
        "#One hot ecoding \n",
        "train_y = encode(cat_train_y , nl)\n",
        "print(train_y.shape)\n",
        "valid_y = encode(cat_val_y , nl)\n",
        "print(valid_y.shape)\n",
        "test_y = encode(test_labels , nl)\n",
        "print(test_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.116582Z",
          "iopub.status.busy": "2023-03-17T18:35:37.116236Z",
          "iopub.status.idle": "2023-03-17T18:35:37.437947Z",
          "shell.execute_reply": "2023-03-17T18:35:37.436614Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.116550Z"
        },
        "id": "4gB5g1rbiuoh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Normalizing the data\n",
        "mean = np.mean(train_x , axis = 0)\n",
        "train_x = (train_x - mean) /255\n",
        "test_x = (flatted_test_images - mean)/255\n",
        "valid_x = (valid_x - mean)/255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nr5kCu-plvfi"
      },
      "outputs": [],
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfc75empL3_4"
      },
      "source": [
        "#Activation functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.446130Z",
          "iopub.status.busy": "2023-03-17T18:35:37.445686Z",
          "iopub.status.idle": "2023-03-17T18:35:37.459778Z",
          "shell.execute_reply": "2023-03-17T18:35:37.458460Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.446088Z"
        },
        "id": "Nb8lRFqmSSY5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Sigmoid \n",
        " \n",
        "def sigmoid(x):\n",
        "    temp = []\n",
        "    # exp_xi=[]\n",
        "    for i in range(len(x)):\n",
        "        # exp_xi=np.exp(-float(x[i]))\n",
        "        result = (1/(1 + np.exp(-(float(x[i])))))\n",
        "        temp.append(result)\n",
        "    return np.array(temp)\n",
        "#Tanh\n",
        "def tanh(x):\n",
        "    temp = []\n",
        "    for i in range(len(x)):\n",
        "      result=np.tanh(x[i])\n",
        "      temp.append(result)\n",
        "\n",
        "    return np.array(temp)\n",
        "#ReLU\n",
        "def relu(x):\n",
        "    temp = []\n",
        "    for i in range(len(x)):\n",
        "      if x[i]>0:\n",
        "        temp.append(x[i])\n",
        "      elif x[i]<=0:\n",
        "        temp.append(0)\n",
        "    return np.array(temp)\n",
        "    \n",
        "#Softmax\n",
        "def softmax(x):\n",
        "  \n",
        "  sum=0\n",
        "  for i in range(len(x)):\n",
        "    sum+=np.exp(float(x[i]))\n",
        "  temp=[]  \n",
        "  for i in range(len(x)):\n",
        "    result=np.exp(float(x[i]))\n",
        "    temp.append(result/sum)\n",
        "\n",
        "  return np.array(temp)\n",
        "\n",
        "#Derivative of Sigmoid\n",
        "def derivative_sigmoid(x):\n",
        "    temp=x*(1 - x)\n",
        "    return temp\n",
        "\n",
        "#Derivative of Tanh\n",
        "def derivative_tanh(x):\n",
        "    cal_tanh=1-np.square(x)\n",
        "    return cal_tanh\n",
        "\n",
        "#Derivative of ReLU\n",
        "def derivative_relu(x):\n",
        "    temp = []\n",
        "    sum=0\n",
        "    for i in range(len(x)):\n",
        "      if x[i]<=0:\n",
        "        temp.append(0)\n",
        "      elif x[i]>0:\n",
        "        temp.append(1)\n",
        "    return np.array(temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ-tlLaeMLtI"
      },
      "source": [
        "#Network initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.461412Z",
          "iopub.status.busy": "2023-03-17T18:35:37.461088Z",
          "iopub.status.idle": "2023-03-17T18:35:37.473393Z",
          "shell.execute_reply": "2023-03-17T18:35:37.471947Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.461383Z"
        },
        "id": "yO6X3QBoMxae",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "def intitialize_zero_input(dim, hl, ol,w,b,d):\n",
        "\n",
        "    for i in range(len(hl)):\n",
        "        hl_size=hl[i]\n",
        "        b.append(np.zeros(hl_size))\n",
        "       \n",
        "        if i == 0:\n",
        "            \n",
        "            w.append(np.zeros((hl_size, d)))\n",
        "        else:\n",
        "            lst_size=hl[i-1]\n",
        "            w.append(np.zeros((hl_size,lst_size )))\n",
        "    return w,b\n",
        "\n",
        "def initialize_zero_output(im, hl, ol,w,b,d):\n",
        "\n",
        "    for i in range(len(ol)):\n",
        "        ol_size=ol[i]\n",
        "        b.append(np.zeros(ol_size))\n",
        "        w.append(np.zeros((ol_size, hl[-1])))\n",
        "    return w,b\n",
        "\n",
        "\n",
        "def initialize_zeros(dim, hl, ol):\n",
        "    w = [np.array([])]\n",
        "    b = [np.array([])]\n",
        "    d = dim\n",
        "  \n",
        "    w,b=intitialize_zero_input(dim, hl, ol,w,b,d)\n",
        "    w,b=initialize_zero_output(dim, hl, ol,w,b,d)\n",
        "\n",
        "    return w, b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq38vwJxHi7u"
      },
      "source": [
        "### Random Initialization And Xavier Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.475489Z",
          "iopub.status.busy": "2023-03-17T18:35:37.475137Z",
          "iopub.status.idle": "2023-03-17T18:35:37.494767Z",
          "shell.execute_reply": "2023-03-17T18:35:37.493341Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.475456Z"
        },
        "id": "5Anplb6Dlvh-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def intitialize_random_input(dim, hl, ol,W,b,d):\n",
        "    np.random.seed(2)\n",
        "\n",
        "    for i in range(len(hl)):\n",
        "        hd_size=hl[i]\n",
        "        b.append(np.random.randn(hd_size))\n",
        "        if(i == 0):\n",
        "          W.append(np.random.randn(hd_size,dim))\n",
        "        else:\n",
        "          lst_size=hl[i - 1]\n",
        "          W.append(np.random.randn(hd_size,lst_size))\n",
        "\n",
        "    return W,b\n",
        "\n",
        "def initialize_random_output(im, hl, ol,W,b,d):\n",
        "\n",
        "    np.random.seed(2)\n",
        "    for i in range(len(ol)):\n",
        "        ol_size=ol[i]\n",
        "        lst_hl_size=hl[-1]\n",
        "        b.append(np.random.randn(ol_size))\n",
        "        W.append(np.random.randn(ol_size,lst_hl_size))\n",
        "    return W,b\n",
        "\n",
        "def random_initialization(dim, hl, ol,W,b,d):\n",
        "   \n",
        "  \n",
        "    W,b=intitialize_random_input(dim, hl, ol,W,b,d)\n",
        "    W,b=initialize_random_output(dim, hl, ol,W,b,d)\n",
        "\n",
        "    return W,b\n",
        "\n",
        "def intitialize_xavier_input(dim, hl, ol,W,b,d):\n",
        "    np.random.seed(2)\n",
        "\n",
        "    for i in range(len(hl)):\n",
        "        hl_size=hl[i]\n",
        "        b.append( np.random.randn(hl_size))\n",
        "        if (i == 0):\n",
        "            W.append(np.random.randn(hl_size,dim ) * np.sqrt(1/dim))\n",
        "        else:\n",
        "            lst_hd_size=hl[i-1]\n",
        "            W.append(np.random.randn(hl_size,lst_hd_size) * np.sqrt(1/lst_hd_size))\n",
        "    return W,b     \n",
        "\n",
        "def initialize_xavier_output(im, hl, ol,W,b,d):\n",
        "    np.random.seed(2)\n",
        "    for i in range(len(ol)):\n",
        "        ol_size=ol[i]\n",
        "        b.append(np.random.randn(ol_size))\n",
        "        lst_ol=hl[-1]\n",
        "        W.append(np.random.randn(ol_size, lst_ol)* np.sqrt(1/lst_ol))\n",
        "    return W,b\n",
        "\n",
        "def xavier_initialization(dim, hl, ol,W,b,d):\n",
        "   \n",
        "  \n",
        "    W,b=intitialize_xavier_input(dim, hl, ol,W,b,d)\n",
        "    W,b=initialize_xavier_output(dim, hl, ol,W,b,d)\n",
        "\n",
        "    return  W,b\n",
        "\n",
        "#Initialize Network \n",
        "def initialize_network(dim, hl, ol, method):\n",
        "  np.random.seed(2)\n",
        "  # Declaring 2d numpy array\n",
        "  W = [np.array([])]\n",
        "  b = [np.array([])]\n",
        " \n",
        "  d = dim\n",
        "  #Setting up the random seed\n",
        "  \n",
        "\n",
        "  #Random Intialization\n",
        "  if(method=='random'):\n",
        "     W,b=random_initialization(dim,hl,ol,W,b,d)\n",
        "      \n",
        "  #Xavier Initialization\n",
        "  else:\n",
        "     W,b= xavier_initialization(dim,hl,ol,W,b,d)\n",
        "\n",
        "  return W,b\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y7VQGKpMQXO"
      },
      "source": [
        "#Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.496906Z",
          "iopub.status.busy": "2023-03-17T18:35:37.496565Z",
          "iopub.status.idle": "2023-03-17T18:35:37.514877Z",
          "shell.execute_reply": "2023-03-17T18:35:37.513714Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.496875Z"
        },
        "id": "yHRXzM_ysJua",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        "def sigmoid_method(w,b,x,a,c,d,h):\n",
        "  num_layers = (len(w)-1)\n",
        "  for i in range(1 , num_layers):\n",
        "            wh=np.dot( w[i], h[i-1] )\n",
        "            c = wh + b[i]\n",
        "            a.append(c)\n",
        "            d = sigmoid(c)\n",
        "            h.append(d)\n",
        "def tanh_method(w,b,x,a,c,d,h):\n",
        "  num_layers = (len(w)-1)\n",
        "  for i in range(1 , num_layers):\n",
        "            c = (w[i]@h[i-1])+b[i]\n",
        "            a.append(c)\n",
        "            h.append(tanh(c))\n",
        "            \n",
        "def identity_method(w,b,x,a,c,d,h):\n",
        "  num_layers = (len(w)-1)\n",
        "  for i in range(1 , num_layers):\n",
        "            c = (w[i]@h[i-1])+b[i]\n",
        "            a.append(c)\n",
        "            h.append(c)\n",
        "\n",
        "\n",
        "def relu_method(w,b,x,a,c,d,h):\n",
        "  num_layers = (len(w)-1)\n",
        "  for i in range(1 , num_layers):\n",
        "            c = (w[i]@h[i-1])+b[i]            \n",
        "            a.append(c)\n",
        "            h.append(relu(c))\n",
        "\n",
        "#Forward Propagation Framework\n",
        "def forward_propagation(w,b,x,method='sigmoid'):\n",
        "    a = [[]]\n",
        "    h = [[]]\n",
        "    # inserting data into first layer\n",
        "    h[0] = x\n",
        "    hl_size=(len(w)-1)\n",
        "    num_layers = hl_size\n",
        "    c = []\n",
        "    d = []\n",
        "    #Sigmoid as activation function in every hidden layer\n",
        "    if method=='sigmoid':\n",
        "        sigmoid_method(w,b,x,a,c,d,h)\n",
        "    #Tanh as activation function in every hidden layer\n",
        "    elif method=='tanh':\n",
        "        tanh_method(w,b,x,a,c,d,h)\n",
        "    #ReLU as activation function in every hidden layer\n",
        "    elif method=='relu':\n",
        "       relu_method(w,b,x,a,c,d,h)\n",
        "    elif method == \"identity\":\n",
        "        identity_method(w,b,x,a,c,d,h)\n",
        "    #Softmax at output Layer\n",
        "    c = w[num_layers] @ h[num_layers-1] + b[num_layers]\n",
        "    d = softmax(c)\n",
        "    a.append(c)\n",
        "    h.append(d)\n",
        "    \n",
        "\n",
        "    return a,h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l1OXNypMUSf"
      },
      "source": [
        "#Backward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.517756Z",
          "iopub.status.busy": "2023-03-17T18:35:37.516585Z",
          "iopub.status.idle": "2023-03-17T18:35:37.532919Z",
          "shell.execute_reply": "2023-03-17T18:35:37.531428Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.517708Z"
        },
        "id": "fTdgFIC4sbnI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "# Loss function cross entropy\n",
        "def cross_entropy_loss_fun(y_pred,y):\n",
        "  cr=y_pred-y\n",
        "  return cr\n",
        "\n",
        "# Loss squared error\n",
        "def sqrd_error_loss_fun(y_pred,y):\n",
        "  y_label = y_pred[np.argmax(y)]\n",
        "  res= 2 * (y_label - 1) * y_label * ( y - y_pred )\n",
        "  return res\n",
        "\n",
        " \n",
        "#Backpropagation Framework\n",
        "def back_prop(W,h,x,y,y_pred,act_fun,loss_fun):\n",
        "  del_W=[[]]\n",
        "  del_b=[[]]\n",
        "\n",
        "  #Computing output grad wrt Cross Entropy Loss function\n",
        "  if loss_fun == \"cross_entropy\" :\n",
        " \n",
        "    del_a = cross_entropy_loss_fun(y_pred,y)\n",
        "    \n",
        "    \n",
        "  #Computing output grad wrt Squared Error Loss function\n",
        "  else:\n",
        " \n",
        "    del_a=sqrd_error_loss_fun(y_pred,y)\n",
        "\n",
        "  for i in range(len(W)-1, 0, -1):\n",
        "\n",
        "    #computing gradients wrt parameters W,b\n",
        "    \n",
        "    db = np.array( del_a )\n",
        "    dot_prod = np.dot(np.matrix(del_a).T , np.matrix(h[i-1]))\n",
        "    dW = np.array(dot_prod)\n",
        "    \n",
        "\n",
        "    #computing gradients wrt below layer activation function\n",
        "    dh = np.dot( np.transpose(W[i]), del_a )\n",
        "\n",
        "    #computing gradients wrt below layer pre-activation function\n",
        "    if act_fun == \"sigmoid\":\n",
        "      del_a = dh *  h[i-1] * (1 - h[i-1])\n",
        "    \n",
        "    elif act_fun == \"tanh\":\n",
        "      del_a = dh * (1 - h[i-1]**2)\n",
        "    \n",
        "    elif act_fun == \"relu\":\n",
        "      del_a = dh * (h[i-1] > 0)\n",
        "    elif act_fun == \"identity\":\n",
        "        pass\n",
        "\n",
        "    del_W.insert(1, dW)\n",
        "    del_b.insert(1, db)\n",
        "\n",
        "  return del_W, del_b\n",
        "\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im9PeUfFHseQ"
      },
      "source": [
        "# Question 3 (24 Marks)\n",
        "Implement the backpropagation algorithm with support for the following optimisation functions\n",
        "\n",
        "* sgd\n",
        "* momentum based gradient descent\n",
        "* nesterov accelerated gradient descent\n",
        "* rmsprop\n",
        "* adam\n",
        "* nadam\n",
        "\n",
        "(12 marks for the backpropagation framework and 2 marks for each of the optimisation algorithms above)\n",
        "\n",
        "We will check the code for implementation and ease of use (e.g., how easy it is to add a new optimisation algorithm such as Eve). Note that the code should be flexible enough to work with different batch sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXprOTMuMaQ1"
      },
      "source": [
        "#Stochastic Gradient Descent optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_8yKZRTH0_0"
      },
      "source": [
        "#### Printing errors and Logging data in Wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.534865Z",
          "iopub.status.busy": "2023-03-17T18:35:37.534430Z",
          "iopub.status.idle": "2023-03-17T18:35:37.550362Z",
          "shell.execute_reply": "2023-03-17T18:35:37.548765Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.534816Z"
        },
        "id": "-A44hpFluYZP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun):\n",
        "\n",
        "    print(\"epoch:\" , e+1 , \" \"+loss_fun+\" \", \"train_acc :\" , train_acc , \"valid_acc :\" , val_acc , \"test_acc :\" , test_acc)\n",
        "    \n",
        "    if loss_fun==\"cross_entropy\":\n",
        "      wandb.log({\n",
        "          \"Epoch\": e+1,\n",
        "          \"Train Loss\": train_loss,\n",
        "          \"Train Acc\": train_acc*100,\n",
        "          \"Valid Loss\": val_loss,\n",
        "          \"Valid Acc\": val_acc*100})\n",
        "    else:\n",
        "      wandb.log({\n",
        "          \"Train Loss (squared_error)\": train_loss,\n",
        "          \"Train Acc (squared_error)\": train_acc*100,\n",
        "          \"Valid Loss (squared_error)\": val_loss,\n",
        "          \"Valid Acc (squared_error)\": val_acc*100})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.552882Z",
          "iopub.status.busy": "2023-03-17T18:35:37.552366Z",
          "iopub.status.idle": "2023-03-17T18:35:37.571528Z",
          "shell.execute_reply": "2023-03-17T18:35:37.569971Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.552827Z"
        },
        "id": "b4B_B7zxsbpx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        "def update_dw_db(tdw,tdb,dw,db):\n",
        "    for i in range(len(tdw)):\n",
        "        dw[i] += tdw[i]\n",
        "        db[i] += tdb[i]\n",
        "    return dw,db\n",
        "   \n",
        "def stochastic_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function implements the Stochastic Gradient Descent (SGD) algorithm for training\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      train_x: Input data for training\n",
        "      train_y: labels for training data\n",
        "      valid_x: Input data for validation\n",
        "      valid_y: labels for validation data\n",
        "      d: List containing the number of neurons in the input layer and each hidden layer\n",
        "      hl: Number of hidden layers\n",
        "      ol: Number of neurons in the output layer\n",
        "      act_fun: Activation function used in the hidden layers\n",
        "      loss_fun: Loss function used in the output layer\n",
        "      epochs: Number of epochs to train the network\n",
        "      eta: Learning rate\n",
        "      strat: Weight initialization strategy\n",
        "      alpha: Parameter for momentum-based optimization\n",
        "      batch: Batch size\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "      w: List of weight matrices for each layer after training\n",
        "      b: List of bias vectors for each layer after training\n",
        "\n",
        "  \"\"\"  \n",
        "  \n",
        "  size_image=784\n",
        "  #Initializing the weights and biases based on given strategy\n",
        "  w,b = initialize_network(d, hl, ol, strat)\n",
        "  counter=0\n",
        " \n",
        "  dw , db = initialize_zeros(size_image,hl,ol)\n",
        "\n",
        "  seen = 0\n",
        "  for e in range(epochs):\n",
        "    counter+=1\n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "\n",
        "      a,h = forward_propagation(w, b, x, act_fun)\n",
        "      last_ele=len(h)-1\n",
        "      y_pred=h[last_ele]\n",
        "      seen += 1\n",
        "     \n",
        "      tdw,tdb=back_prop(w, h, x, y, y_pred, act_fun, loss_fun)\n",
        "\n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "\n",
        "      if(seen==batch or it==len(train_x)-1):\n",
        "        seen = 0\n",
        "        for i in range(len(w)):\n",
        "            weight=w[i]\n",
        "            deriv=dw[i]\n",
        "            # w[i] = weight - eta * np.array(deriv)\n",
        "            w[i] = weight - eta * np.array(deriv) - eta*alpha*weight\n",
        "\n",
        "        for i in range(len(b)):\n",
        "            bias=b[i]\n",
        "            deriv=db[i]\n",
        "            b[i] = bias - eta * np.array(deriv) - eta*alpha*bias\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    #Getting train,val,test accuracies and losses and predictions with true labels\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(w, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(w, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(w, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "   \n",
        "  return w,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7JpBnmAMhNU"
      },
      "source": [
        "#Momentum Based Gradient Descent "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.573601Z",
          "iopub.status.busy": "2023-03-17T18:35:37.573169Z",
          "iopub.status.idle": "2023-03-17T18:35:37.592182Z",
          "shell.execute_reply": "2023-03-17T18:35:37.590617Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.573562Z"
        },
        "id": "wYT8Ed0eVIwu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        "\n",
        " \n",
        "def momentum_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function performs momentum gradient descent to optimize the weights and biases of a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      gamma: Gamma value for the optimizer\n",
        "      eta: learning rate\n",
        "      strat: weight initialization strategy\n",
        "      alpha: momentum hyperparameter\n",
        "      \n",
        "  \"\"\"\n",
        "\n",
        "  gamma=0.9\n",
        "  seen=0\n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "  counter=0\n",
        "  dw , db = initialize_zeros(784,hl,ol)\n",
        "  prev_w , prev_b = initialize_zeros(784,hl,ol)\n",
        "  for e in range(epochs):\n",
        "    counter+=1\n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      seen+=1\n",
        "      a,h = forward_propagation(W, b, x, act_fun)\n",
        "      y_pred=h[len(h)-1]\n",
        "      \n",
        "      tdw,tdb=back_prop(W, h, x, y, y_pred, act_fun, loss_fun)\n",
        "  \n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "    \n",
        "      if(seen==batch or it==len(train_x)-1):\n",
        "        seen=0\n",
        "        for i in range(len(W)):\n",
        "            weight = W[i]\n",
        "            deriv = dw[i]\n",
        "            new_weight = weight - eta * np.array(deriv) - gamma * prev_w[i]- eta*alpha*weight\n",
        "            new_prev_w = eta * np.array(deriv) + gamma * prev_w[i]\n",
        "            W[i] = new_weight\n",
        "            prev_w[i] = new_prev_w\n",
        "\n",
        "\n",
        "        for i in range(len(b)):\n",
        "            bias = b[i]\n",
        "            deriv = db[i]\n",
        "            new_bias = bias - eta * np.array(deriv) - gamma * prev_b[i] - eta*alpha*bias\n",
        "            new_prev_b = eta * np.array(deriv) + gamma * prev_b[i]\n",
        "            b[i] = new_bias\n",
        "            prev_b[i] = new_prev_b\n",
        "            \n",
        "            dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybb-fTh2MlKf"
      },
      "source": [
        "#Nesterov Accelerated Gradient Descent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.594713Z",
          "iopub.status.busy": "2023-03-17T18:35:37.594211Z",
          "iopub.status.idle": "2023-03-17T18:35:37.615232Z",
          "shell.execute_reply": "2023-03-17T18:35:37.614092Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.594662Z"
        },
        "id": "WOFtP3b3r6lo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def cal_v_w_v_b(W,v_w,v_b,gamma,prev_w,prev_b):\n",
        "    for i in range(len(W)):\n",
        "        v_w[i] = gamma*prev_w[i]\n",
        "        v_b[i] = gamma*prev_b[i]\n",
        "    return v_w,v_b\n",
        "    \n",
        "def cal_t_w_t_b(W,tw,tb,v_w,v_b,b):\n",
        "    for i in range(len(W)):\n",
        "        tw[i] = W[i] - v_w[i]\n",
        "        tb[i] = b[i] - v_b[i]\n",
        "    return tw,tb\n",
        "\n",
        "def nesterov_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function performs nesterov gradient descent to optimize the weights and biases of a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      gamma: Gamma value for the optimizer\n",
        "      eta: learning rate\n",
        "      strat: weight initialization strategy\n",
        "      alpha: momentum hyperparameter\n",
        "      \n",
        "  \"\"\" \n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "\n",
        "  gamma=0.9\n",
        "  seen=0\n",
        "  \n",
        "  prev_w , prev_b = initialize_zeros(784,hl,ol)\n",
        "  v_w , v_b =initialize_zeros(784,hl,ol)\n",
        "\n",
        "  dw , db = initialize_zeros(784,hl,ol)\n",
        "  tw , tb = initialize_zeros(784,hl,ol)\n",
        "\n",
        "  for e in range(epochs):\n",
        "\n",
        "     \n",
        "    v_w,v_b = cal_v_w_v_b(W,v_w,v_b,gamma,prev_w,prev_b)\n",
        "    \n",
        "    tw,tb = cal_t_w_t_b(W,tw,tb,v_w,v_b,b)\n",
        "     \n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      a,h = forward_propagation(tw, tb, x, act_fun)\n",
        "      hl_size=len(h)-1\n",
        "      y_pred=h[hl_size]\n",
        "      seen+=1\n",
        "      tdw,tdb=back_prop(tw, h, x, y, y_pred, act_fun, loss_fun)\n",
        "      \n",
        "      update_dw_db(tdw,tdb,dw,db)\n",
        "\n",
        "      if seen==batch or it == len(train_x)-1:\n",
        "        seen=0\n",
        "        for i in range(len(W)):\n",
        "          weight = W[i]\n",
        "          deriv = dw[i]\n",
        "          v_w[i] = gamma*prev_w[i] + eta*np.array(deriv) - eta*alpha*weight\n",
        "          W[i] = weight - v_w[i]\n",
        "          tw[i] = W[i]\n",
        "          prev_w = v_w\n",
        "\n",
        "        for i in range(len(b)):\n",
        "          bias = b[i]\n",
        "          deriv = db[i]\n",
        "          v_b[i] = gamma*prev_b[i] + eta*np.array(deriv)- eta*alpha*bias\n",
        "          b[i] = bias - v_b[i]\n",
        "          tb[i] = b[i]\n",
        "          prev_b = v_b\n",
        "\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRsDnJLyM7xm"
      },
      "source": [
        "#RMS_Prop Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.618766Z",
          "iopub.status.busy": "2023-03-17T18:35:37.617111Z",
          "iopub.status.idle": "2023-03-17T18:35:37.637237Z",
          "shell.execute_reply": "2023-03-17T18:35:37.635658Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.618694Z"
        },
        "id": "iCF8hfEfZrRo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def rmsprop(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch,beta = 0.9):\n",
        "  \"\"\"\n",
        "    This function performs Root Mean Square Propagation (RMSprop)  to optimize the weights and biases of a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      gamma: Gamma value for the optimizer\n",
        "      beta : exponential decay rate\n",
        "      eta: learning rate\n",
        "      strat: weight initialization strategy\n",
        "      alpha: momentum hyperparameter\n",
        "      \n",
        "  \"\"\" \n",
        "  prev_w , prev_b = initialize_zeros(784,hl,ol)\n",
        "  eps = 1e-8 \n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "  seen=0\n",
        "  \n",
        "  prev_w , prev_b = initialize_zeros(784,hl,ol)\n",
        "  dw , db = initialize_zeros(784,hl,ol)\n",
        "   \n",
        "\n",
        "  for e in range(epochs):\n",
        "  \n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      \n",
        "      a,h = forward_propagation(W, b, x, act_fun)\n",
        "      hl_size=len(h)-1\n",
        "      y_pred=h[hl_size]\n",
        "      seen+=1\n",
        "      tdw,tdb=back_prop(W, h, x, y, y_pred, act_fun, loss_fun)\n",
        "      \n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "      \n",
        "      if seen==batch or it == len(train_x)-1:\n",
        "\n",
        "        seen=0\n",
        "        for i, (dw_i, db_i) in enumerate(zip(dw,db)):\n",
        "          prev_w[i] = beta*prev_w[i] + (1-beta)*(dw_i**2)\n",
        "          prev_b[i] = beta*prev_b[i] + (1-beta)*(db_i**2)\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          weight=W[i]\n",
        "          deriv=dw[i]\n",
        "          W[i] = weight - (eta / np.sqrt(prev_w[i] + eps)) * np.array(deriv) - eta*alpha*weight\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          bias=b[i]\n",
        "          deriv=db[i]\n",
        "          b[i] = bias - (eta / np.sqrt(prev_b[i] + eps)) * np.array(deriv) - eta*alpha*bias\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIlcCzcJNOdq"
      },
      "source": [
        "#Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.640021Z",
          "iopub.status.busy": "2023-03-17T18:35:37.639235Z",
          "iopub.status.idle": "2023-03-17T18:35:37.662312Z",
          "shell.execute_reply": "2023-03-17T18:35:37.660815Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.639976Z"
        },
        "id": "qpjZJAhk47Sy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def adaptive_moments(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function implements the Adaptive Moments (Adam) optimization algorithm for training a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      beta1, beta2 : exponential decay rate\n",
        "      strat: weight initialization strategy\n",
        "     \n",
        "  \"\"\"\n",
        "  dimention=784\n",
        "  dw , db = initialize_zeros(dimention,hl,ol)\n",
        "  m_w , m_b = initialize_zeros(dimention,hl,ol)\n",
        "  eps=1e-8\n",
        "  v_w , v_b = initialize_zeros(dimention,hl,ol)\n",
        "  beta1 , beta2 =  0.9 , 0.99\n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "  m_w_hat , m_b_hat = initialize_zeros(dimention,hl,ol)\n",
        "  v_w_hat , v_b_hat = initialize_zeros(dimention,hl,ol)\n",
        "  seen=0\n",
        "  c=0\n",
        "\n",
        "  for e in range(epochs):\n",
        "  \n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      \n",
        "      a,h = forward_propagation(W, b, x, act_fun)\n",
        "      hl_size=len(h)-1\n",
        "      y_pred=h[hl_size]\n",
        "      seen+=1\n",
        "\n",
        "      tdw,tdb=back_prop(W, h, x, y, y_pred, act_fun, loss_fun)\n",
        "      \n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "\n",
        "      if seen==batch or it == len(train_x)-1:\n",
        "\n",
        "        seen=0\n",
        "        c+=1\n",
        "        for i in range(len(W)):\n",
        "          dw_i=dw[i]\n",
        "          db_i=db[i]\n",
        "          m_w[i] = beta1 * m_w[i] + (1 - beta1) * dw_i\n",
        "          m_b[i] = beta1 * m_b[i] + (1 - beta1) * db_i\n",
        "          v_w[i] = beta2 * v_w[i] + (1 - beta2) * dw_i ** 2\n",
        "          v_b[i] = beta2 * v_b[i] + (1 - beta2) * db_i ** 2\n",
        "\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          denom1=(1 - np.power(beta1,c))\n",
        "          denom2=(1 - np.power(beta2,c))\n",
        "\n",
        "          m_w_hat[i] = m_w[i] / denom1\n",
        "          m_b_hat[i] = m_b[i] / denom1\n",
        "\n",
        "          v_w_hat[i] = v_w[i] / denom2\n",
        "          v_b_hat[i] = v_b[i] / denom2\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          weight=W[i]\n",
        "          deriv=dw[i]\n",
        "          W[i] = weight - (eta / np.sqrt(v_w_hat[i] + eps)) * m_w_hat[i] - eta*alpha*weight\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          bias=b[i]\n",
        "          deriv=db[i]\n",
        "          b[i] = bias - (eta / np.sqrt(v_b_hat[i] + eps)) * m_b_hat[i] - eta*alpha*bias\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfDrDkl0NTfM"
      },
      "source": [
        "#Nadam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.667067Z",
          "iopub.status.busy": "2023-03-17T18:35:37.665668Z",
          "iopub.status.idle": "2023-03-17T18:35:37.688680Z",
          "shell.execute_reply": "2023-03-17T18:35:37.687603Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.666982Z"
        },
        "id": "dScKlrVAMjHu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def nadam(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function implements the Nesterov-accelerated Adaptive Moment  (NAdam) optimization algorithm for training a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      beta1, beta2 : exponential decay rates\n",
        "      strat: weight initialization strategy\n",
        "     \n",
        "  \"\"\"\n",
        "  dimention=784\n",
        "  eps=1e-8 \n",
        "  beta1 , beta2 =  0.9 , 0.99\n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "  dw , db = initialize_zeros(dimention,hl,ol)\n",
        "  m_w , m_b = initialize_zeros(dimention,hl,ol)\n",
        "  v_w , v_b = initialize_zeros(dimention,hl,ol)\n",
        " \n",
        "  m_w_hat , m_b_hat = initialize_zeros(dimention,hl,ol)\n",
        "  v_w_hat , v_b_hat = initialize_zeros(dimention,hl,ol)\n",
        "  seen=0\n",
        "  c=0\n",
        "\n",
        "  for e in range(epochs):\n",
        "  \n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      \n",
        "      a,h = forward_propagation(W, b, x, act_fun)\n",
        "      y_pred=h[len(h)-1]\n",
        "      \n",
        "      tdw,tdb=back_prop(W, h, x, y, y_pred, act_fun, loss_fun)\n",
        "      \n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "      seen+=1\n",
        "      if seen==batch or it == len(train_x)-1:\n",
        "\n",
        "        seen=0\n",
        "        c+=1\n",
        "        for i, (dw_i, db_i) in enumerate(zip(dw, db)):\n",
        "          m_w[i] = beta1 * m_w[i] + (1-beta1) * dw_i\n",
        "          m_b[i] = beta1 * m_b[i] + (1-beta1) * db_i\n",
        "\n",
        "          v_w[i] = beta2 * v_w[i] + (1-beta2) * (dw_i**2)\n",
        "          v_b[i] = beta2 * v_b[i] + (1-beta2) * (db_i**2)\n",
        "\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          denom1=(1 - np.power(beta1,c))\n",
        "          denom2=(1 - np.power(beta2,c))\n",
        "\n",
        "          m_w_hat[i] = ( (beta1 * m_w[i]) + ( (1 - beta1) * dw[i] ) )/ denom1\n",
        "          m_b_hat[i] = ( (beta1 * m_b[i]) + ( (1 - beta1) * db[i] ) )/ denom1\n",
        "\n",
        "          v_w_hat[i] = v_w[i] / denom2\n",
        "          v_b_hat[i] = v_b[i] / denom2\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          weight=W[i]\n",
        "          deriv=dw[i]\n",
        "          W[i] = weight - (eta / np.sqrt(v_w_hat[i] + eps)) * m_w_hat[i] - eta*alpha*weight\n",
        "\n",
        "        for i in range(len(b)):\n",
        "          bias=b[i]\n",
        "          deriv=db[i]\n",
        "          b[i] = bias - (eta / np.sqrt(v_b_hat[i] + eps)) * m_b_hat[i] - eta*alpha*bias\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-lW4pgQIZag"
      },
      "source": [
        "#Confusion_matrix \n",
        "(Implemented in other file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.690981Z",
          "iopub.status.busy": "2023-03-17T18:35:37.690619Z",
          "iopub.status.idle": "2023-03-17T18:35:40.728758Z",
          "shell.execute_reply": "2023-03-17T18:35:40.727423Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.690944Z"
        },
        "id": "0SW5mfI0JWAp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_confusion_matrix(y_true , y_pred , class_names , figsize=(20,20)):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=class_names)\n",
        "    fontsize = 14\n",
        "    r=class_names[::-1]\n",
        "    #z_text = [[str(y_true) for y_true in y_pred] for y_pred in cm]\n",
        "\n",
        "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    h = [ [0 for _ in range(len(class_names))] for _ in range(len(class_names)) ]\n",
        "    #h = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(1,nrows+1):\n",
        "        for j in range(1,ncols+1):\n",
        "            c = cm[i-1, j-1]\n",
        "            p = cm_perc[i-1, j-1]\n",
        "            if i == j:\n",
        "                s = cm_sum[i-1]\n",
        "                annot[i-1, j-1] = '%.1f%% <br> %d/%d' % (p, c, s)\n",
        "                h[i-1][j-1] = '%d %s are correctly classified' % (c,labels[i-1])\n",
        "            elif c == 0:\n",
        "                annot[i-1, j-1] = ''\n",
        "                h[i-1][j-1] = ''\n",
        "            else:\n",
        "                annot[i-1, j-1] = '%.1f%% <br> %d' % (p, c)\n",
        "                h[i-1][j-1] = '%d %s are wrongly classified as %s' % (c,labels[i-1],labels[j-1])\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(cm , x = class_names, y = class_names , text=h,annotation_text = annot , hoverinfo='text' ,colorscale ='blugrn_R')\n",
        "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
        "    \n",
        "   \n",
        "    # add custom xaxis title\n",
        "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),x=0.5,y=-0.15,showarrow=False,text=\"Predicted value\",xref=\"paper\",yref=\"paper\"))\n",
        "\n",
        "    # add custom yaxis title\n",
        "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),x=-0.35,y=0.5,showarrow=False,text=\"Real value\",textangle=-90,xref=\"paper\",yref=\"paper\"))\n",
        "\n",
        "    # adjust margins to make room for yaxis title\n",
        "    fig.update_layout(margin=dict(t=50, l=200))\n",
        "    fig.update_annotations(font_size=14)\n",
        "   \n",
        "    fig['data'][0]['showscale'] = True\n",
        "    fig.update_xaxes(side=\"top\")\n",
        "    fig.show()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myOelQjrNW2f"
      },
      "source": [
        "#Predictions and accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.731245Z",
          "iopub.status.busy": "2023-03-17T18:35:40.730399Z",
          "iopub.status.idle": "2023-03-17T18:35:40.748956Z",
          "shell.execute_reply": "2023-03-17T18:35:40.747764Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.731193Z"
        },
        "id": "ULyXvX_Qr8Sh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predict_sigmoid(a,h,W, b, X, y, method, loss_fun,num_layers):\n",
        "    for i in range(1 , num_layers):\n",
        "        a = np.dot( W[i], h ) + b[i]\n",
        "        h = sigmoid(a)\n",
        "    return a,h\n",
        "\n",
        "def predict_tanh(a,h,W, b, X, y, method, loss_fun,num_layers):\n",
        "    for i in range(1 , num_layers):\n",
        "        a = np.dot( W[i], h ) + b[i]\n",
        "        h = tanh(a)\n",
        "    return a,h\n",
        "\n",
        "def predict_relu(a,h,W, b, X, y, method, loss_fun,num_layers):\n",
        "    for i in range(1 , num_layers):\n",
        "        a = np.dot( W[i], h ) + b[i]\n",
        "        h = relu(a)\n",
        "    return a,h\n",
        "\n",
        "def predict_identity(a,h,W, b, X, y, method, loss_fun,num_layers):\n",
        "    return a,h\n",
        "\n",
        "def get_predictions_accuracy(W, b, X, y, method, loss_fun):\n",
        "  sum,loss=0,0\n",
        "  yhat = []\n",
        "  yt = []\n",
        "  for dp in range(len(X)):\n",
        "    a = []\n",
        "    h = []\n",
        "    h = X[dp] \n",
        "    num_layers = (len(W)-1)\n",
        "\n",
        "    if method=='sigmoid':\n",
        "        a,h = predict_sigmoid(a,h,W, b, X, y, method, loss_fun,num_layers)\n",
        "\n",
        "    elif method=='tanh':\n",
        "        a,h = predict_tanh(a,h,W, b, X, y, method, loss_fun,num_layers)\n",
        "\n",
        "    elif method=='relu':\n",
        "        a,h = predict_relu(a,h,W, b, X, y, method, loss_fun,num_layers)\n",
        "        \n",
        "    elif method=='identity':\n",
        "        a,h = predict_relu(a,h,W, b, X, y, method, loss_fun,num_layers)\n",
        "\n",
        "    a = np.dot( W[num_layers], h ) + b[num_layers]\n",
        "    y_pred = softmax(a)\n",
        "\n",
        "    ytrue = y[dp]\n",
        "    if(ytrue[np.argmax(y_pred)]==1):\n",
        "      sum=sum+1\n",
        "    \n",
        "    if loss_fun == \"cross_entropy\":\n",
        "      loss += -np.sum(ytrue*np.log(y_pred))\n",
        "    else:\n",
        "      loss += np.sum((ytrue-y_pred)**2)\n",
        "\n",
        "    yhat.append(labels[np.argmax(y_pred)])\n",
        "    yt.append(labels[np.argmax(ytrue)])\n",
        "\n",
        "  acc=sum/len(X)\n",
        "  loss=loss/len(X)\n",
        "\n",
        "  return acc,loss,yt,yhat\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sweep configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.751347Z",
          "iopub.status.busy": "2023-03-17T18:35:40.750667Z",
          "iopub.status.idle": "2023-03-17T18:35:40.775542Z",
          "shell.execute_reply": "2023-03-17T18:35:40.774385Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.751306Z"
        },
        "id": "lyrZVhaeso1u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "sweep_config_temp={\n",
        "  \"name\": \"Assignment_1\",\n",
        "  \"method\": \"bayes\",\n",
        "  \"metric\": {\n",
        "      \"name\": \"Valid Acc\",\n",
        "      \"goal\": \"maximize\"   \n",
        "    },\n",
        "  \"parameters\": {\n",
        "        \"epochs\": {\n",
        "            \"values\": [ 5, 10]\n",
        "        },\n",
        "        \"hidden_layers\":{\n",
        "            \"values\":[3, 4, 5]\n",
        "        },\n",
        "        \"hidden_layer_size\":{\n",
        "            \"values\":[32, 64, 128]  \n",
        "        },\n",
        "        \"eta\":{\n",
        "            \"values\":[0.001,0.0001]\n",
        "        },\n",
        "        \"optimizer\":{\n",
        "            \"values\":[ 'sgd', 'mgd', 'nag', 'rmsprop', 'adam', 'nadam']\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\": [16, 32, 64]\n",
        "        },\n",
        "        \"alpha\":{\n",
        "            \"values\":[ 0, 0.0005, 0.5]\n",
        "        },\n",
        "        \"strat\":{\n",
        "            \"values\":['xavier','random']\n",
        "        },\n",
        "        \"act_fun\":{\n",
        "            \"values\":[ 'sigmoid', 'tanh','relu']\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.777910Z",
          "iopub.status.busy": "2023-03-17T18:35:40.776853Z",
          "iopub.status.idle": "2023-03-17T18:35:40.789906Z",
          "shell.execute_reply": "2023-03-17T18:35:40.788640Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.777857Z"
        },
        "id": "fiT72DwmvD-c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def helper(W , b , train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun):\n",
        "\n",
        "  test_acc_ce , test_loss_ce , ytrue , ypred = get_predictions_accuracy(W, b, test_x, test_y, config.act_fun, loss_fun[0])\n",
        "\n",
        "  # cmat = get_confusion_matrix(ytrue , ypred , labels , figsize=(20,20))\n",
        "\n",
        "  if len(loss_fun)==1:\n",
        "    wandb.log({\n",
        "        \"test_acc\" : test_acc_ce*100,\n",
        "        \"test_loss\" : test_loss_ce,\n",
        "#         \"Confusion_Matrix\": cmat  \n",
        "        })\n",
        "  else:\n",
        "    W , b = second(train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun[1])\n",
        "    test_acc_sq , test_loss_sq , ytrue_sq , ypred_sq = get_predictions_accuracy(W, b, test_x, test_y, config.act_fun, loss_fun[1])\n",
        "    wandb.log({\n",
        "        \"test_acc\" : test_acc_ce*100,\n",
        "        \"test_loss\" : test_loss_ce,\n",
        "        \"test_acc (squared error)\" : test_acc_sq*100,\n",
        "        \"test_loss (squared error)\" : test_loss_sq,\n",
        "        # \"Confusion_Matrix\": cmat\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_WLZGtLTw0s"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.792522Z",
          "iopub.status.busy": "2023-03-17T18:35:40.791739Z",
          "iopub.status.idle": "2023-03-17T18:35:40.806606Z",
          "shell.execute_reply": "2023-03-17T18:35:40.805354Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.792470Z"
        },
        "id": "4OPrOA_8vED1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def second(train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun):\n",
        "\n",
        "  act_fun = config.act_fun\n",
        "  epochs = config.epochs\n",
        "  strat = config.strat\n",
        "  alpha = config.alpha\n",
        "  eta = config.eta\n",
        "  batch_size = config.batch_size\n",
        "  optimizer = config.optimizer\n",
        "\n",
        "  if optimizer == 'sgd':\n",
        "    W , b = stochastic_gradient_descent( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "\n",
        "  elif optimizer == 'rmsprop':\n",
        "    W , b = rmsprop( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "\n",
        "  elif optimizer == 'mgd':\n",
        "    W , b = momentum_gradient_descent( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "  \n",
        "  elif optimizer == 'nag':\n",
        "    W , b = nesterov_gradient_descent( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "  \n",
        "  elif optimizer == 'adam':\n",
        "    W , b = adaptive_moments( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "\n",
        "  elif optimizer == 'nadam':\n",
        "    W , b = nadam( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdlm_S-Q0iO1"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.808566Z",
          "iopub.status.busy": "2023-03-17T18:35:40.808158Z",
          "iopub.status.idle": "2023-03-17T18:35:40.820258Z",
          "shell.execute_reply": "2023-03-17T18:35:40.819174Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.808531Z"
        },
        "id": "ceIkf_3u0g95",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  run=wandb.init()\n",
        "  config = wandb.config\n",
        "\n",
        "  loss_fun=[\"cross_entropy\"]\n",
        "\n",
        "  hl = [config.hidden_layer_size]*config.hidden_layers\n",
        "  ol = [len(train_y[0])]\n",
        "\n",
        "  name = \"hl_\" + str(config.hidden_layers) + \"_bs_\" + str(config.batch_size) + \"_ac_\" + config.act_fun\n",
        "  run.name = name\n",
        "\n",
        "  W,b = second(train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun[0])\n",
        "  helper(W , b , train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun)\n",
        "  \n",
        "  #Showing one image of each class (Question - 1)\n",
        "  \n",
        "  run.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DaYRj2Y42H5B"
      },
      "source": [
        "# For running sweep in Wandb "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.823251Z",
          "iopub.status.busy": "2023-03-17T18:35:40.822286Z",
          "iopub.status.idle": "2023-03-17T18:35:41.138894Z",
          "shell.execute_reply": "2023-03-17T18:35:41.137549Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.823199Z"
        },
        "id": "GQodczbf1r6v",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sweep_id = wandb.sweep(sweep_config_temp, entity=\"cs22m035\", project=\"Assignment_1\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logging in Question 1 in Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:41.140690Z",
          "iopub.status.busy": "2023-03-17T18:35:41.140354Z"
        },
        "id": "Wtd2Z3fZ1r91",
        "outputId": "7d1c8227-ed45-478b-8fab-582dc2fd005e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "wandb.init(entity=\"cs22m035\", project=\"Assignment_1\")\n",
        "wandb.run.name = \"Q1\"\n",
        "show_images(train_images , train_labels , labels)\n",
        "wandb.agent(sweep_id, train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ploting Confusion Matrix for best configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eoT3bGm8I46Z",
        "outputId": "cdaa8977-10b8-4c26-bf35-b2445a403850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 2  cross_entropy  train_acc : 0.8830370370370371 valid_acc : 0.8765 test_acc : 0.861\n",
            "epoch: 3  cross_entropy  train_acc : 0.895425925925926 valid_acc : 0.883 test_acc : 0.8679\n",
            "epoch: 4  cross_entropy  train_acc : 0.9019259259259259 valid_acc : 0.8845 test_acc : 0.8713\n",
            "epoch: 5  cross_entropy  train_acc : 0.9081111111111111 valid_acc : 0.888 test_acc : 0.8764\n",
            "epoch: 6  cross_entropy  train_acc : 0.91 valid_acc : 0.8868333333333334 test_acc : 0.8749\n",
            "epoch: 7  cross_entropy  train_acc : 0.9125 valid_acc : 0.8871666666666667 test_acc : 0.8733\n",
            "epoch: 8  cross_entropy  train_acc : 0.9152592592592592 valid_acc : 0.8836666666666667 test_acc : 0.8731\n",
            "epoch: 9  cross_entropy  train_acc : 0.9235740740740741 valid_acc : 0.8885 test_acc : 0.8781\n",
            "epoch: 10  cross_entropy  train_acc : 0.9169074074074074 valid_acc : 0.876 test_acc : 0.8675\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:uxeautbb) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Acc</td><td>▁▃▅▅▆▆▇▇█▇</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▂▂▁▂</td></tr><tr><td>Valid Acc</td><td>▁▅▆▇███▇█▄</td></tr><tr><td>Valid Loss</td><td>█▄▂▂▁▂▄▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Acc</td><td>91.69074</td></tr><tr><td>Train Loss</td><td>0.22367</td></tr><tr><td>Valid Acc</td><td>87.6</td></tr><tr><td>Valid Loss</td><td>0.37771</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cerulean-frog-681</strong> at: <a href='https://wandb.ai/cs22m035/Assignment_1/runs/uxeautbb' target=\"_blank\">https://wandb.ai/cs22m035/Assignment_1/runs/uxeautbb</a><br/>Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230319_142107-uxeautbb/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:uxeautbb). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_150300-5kch5zum</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m035/confusion/runs/5kch5zum' target=\"_blank\">comic-plant-7</a></strong> to <a href='https://wandb.ai/cs22m035/confusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m035/confusion' target=\"_blank\">https://wandb.ai/cs22m035/confusion</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m035/confusion/runs/5kch5zum' target=\"_blank\">https://wandb.ai/cs22m035/confusion/runs/5kch5zum</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d77db4d7-d461-43f2-8063-808171e3efb4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d77db4d7-d461-43f2-8063-808171e3efb4\")) {                    Plotly.newPlot(                        \"d77db4d7-d461-43f2-8063-808171e3efb4\",                        [{\"colorscale\":[[0.0,\"rgb(29, 79, 96)\"],[0.16666666666666666,\"rgb(38, 107, 110)\"],[0.3333333333333333,\"rgb(54, 135, 122)\"],[0.5,\"rgb(77, 162, 132)\"],[0.6666666666666666,\"rgb(109, 188, 144)\"],[0.8333333333333334,\"rgb(150, 210, 164)\"],[1.0,\"rgb(196, 230, 195)\"]],\"hoverinfo\":\"text\",\"reversescale\":false,\"showscale\":true,\"text\":[[\"4686 T-shirt/Top are correctly classified\",\"20 T-shirt/Top are wrongly classified as Trouser\",\"73 T-shirt/Top are wrongly classified as Pullover\",\"184 T-shirt/Top are wrongly classified as Dress\",\"25 T-shirt/Top are wrongly classified as Coat\",\"4 T-shirt/Top are wrongly classified as Sandal\",\"386 T-shirt/Top are wrongly classified as Shirt\",\"\",\"22 T-shirt/Top are wrongly classified as Bag\",\"\"],[\"\",\"5359 Trouser are correctly classified\",\"2 Trouser are wrongly classified as Pullover\",\"30 Trouser are wrongly classified as Dress\",\"4 Trouser are wrongly classified as Coat\",\"1 Trouser are wrongly classified as Sandal\",\"1 Trouser are wrongly classified as Shirt\",\"\",\"3 Trouser are wrongly classified as Bag\",\"\"],[\"25 Pullover are wrongly classified as T-shirt/Top\",\"2 Pullover are wrongly classified as Trouser\",\"4884 Pullover are correctly classified\",\"31 Pullover are wrongly classified as Dress\",\"197 Pullover are wrongly classified as Coat\",\"\",\"258 Pullover are wrongly classified as Shirt\",\"\",\"3 Pullover are wrongly classified as Bag\",\"\"],[\"20 Dress are wrongly classified as T-shirt/Top\",\"99 Dress are wrongly classified as Trouser\",\"23 Dress are wrongly classified as Pullover\",\"4967 Dress are correctly classified\",\"253 Dress are wrongly classified as Coat\",\"\",\"30 Dress are wrongly classified as Shirt\",\"3 Dress are wrongly classified as Sneaker\",\"5 Dress are wrongly classified as Bag\",\"\"],[\"1 Coat are wrongly classified as T-shirt/Top\",\"3 Coat are wrongly classified as Trouser\",\"591 Coat are wrongly classified as Pullover\",\"60 Coat are wrongly classified as Dress\",\"4516 Coat are correctly classified\",\"1 Coat are wrongly classified as Sandal\",\"208 Coat are wrongly classified as Shirt\",\"\",\"18 Coat are wrongly classified as Bag\",\"2 Coat are wrongly classified as Ankle Boot\"],[\"\",\"\",\"\",\"\",\"\",\"5115 Sandal are correctly classified\",\"\",\"151 Sandal are wrongly classified as Sneaker\",\"4 Sandal are wrongly classified as Bag\",\"130 Sandal are wrongly classified as Ankle Boot\"],[\"425 Shirt are wrongly classified as T-shirt/Top\",\"7 Shirt are wrongly classified as Trouser\",\"371 Shirt are wrongly classified as Pullover\",\"130 Shirt are wrongly classified as Dress\",\"196 Shirt are wrongly classified as Coat\",\"\",\"4246 Shirt are correctly classified\",\"2 Shirt are wrongly classified as Sneaker\",\"23 Shirt are wrongly classified as Bag\",\"\"],[\"\",\"\",\"\",\"\",\"\",\"5 Sneaker are wrongly classified as Sandal\",\"\",\"5015 Sneaker are correctly classified\",\"1 Sneaker are wrongly classified as Bag\",\"379 Sneaker are wrongly classified as Ankle Boot\"],[\"\",\"1 Bag are wrongly classified as Trouser\",\"2 Bag are wrongly classified as Pullover\",\"3 Bag are wrongly classified as Dress\",\"4 Bag are wrongly classified as Coat\",\"\",\"2 Bag are wrongly classified as Shirt\",\"7 Bag are wrongly classified as Sneaker\",\"5381 Bag are correctly classified\",\"\"],[\"\",\"\",\"\",\"\",\"\",\"3 Ankle Boot are wrongly classified as Sandal\",\"\",\"52 Ankle Boot are wrongly classified as Sneaker\",\"1 Ankle Boot are wrongly classified as Bag\",\"5344 Ankle Boot are correctly classified\"]],\"x\":[\"T-shirt/Top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"],\"y\":[\"T-shirt/Top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"],\"z\":[[4686,20,73,184,25,4,386,0,22,0],[0,5359,2,30,4,1,1,0,3,0],[25,2,4884,31,197,0,258,0,3,0],[20,99,23,4967,253,0,30,3,5,0],[1,3,591,60,4516,1,208,0,18,2],[0,0,0,0,0,5115,0,151,4,130],[425,7,371,130,196,0,4246,2,23,0],[0,0,0,0,0,5,0,5015,1,379],[0,1,2,3,4,0,2,7,5381,0],[0,0,0,0,0,3,0,52,1,5344]],\"type\":\"heatmap\"}],                        {\"annotations\":[{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"86.8% <br> 4686/5400\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 20\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"1.4% <br> 73\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"3.4% <br> 184\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.5% <br> 25\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 4\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"7.1% <br> 386\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 22\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"99.2% <br> 5359/5400\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.6% <br> 30\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 4\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.5% <br> 25\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"90.4% <br> 4884/5400\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.6% <br> 31\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"3.6% <br> 197\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"4.8% <br> 258\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 20\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"1.8% <br> 99\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 23\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"92.0% <br> 4967/5400\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"4.7% <br> 253\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.6% <br> 30\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 5\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"10.9% <br> 591\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"1.1% <br> 60\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"83.6% <br> 4516/5400\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"3.9% <br> 208\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.3% <br> 18\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"94.7% <br> 5115/5400\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"2.8% <br> 151\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 4\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"2.4% <br> 130\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"7.9% <br> 425\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 7\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"6.9% <br> 371\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"2.4% <br> 130\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"3.6% <br> 196\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"78.6% <br> 4246/5400\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 23\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 5\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"92.9% <br> 5015/5400\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"7.0% <br> 379\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 4\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 7\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"99.6% <br> 5381/5400\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"1.0% <br> 52\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"99.0% <br> 5344/5400\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Predicted value\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.15,\"yref\":\"paper\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Real value\",\"textangle\":-90,\"x\":-0.35,\"xref\":\"paper\",\"y\":0.5,\"yref\":\"paper\"}],\"xaxis\":{\"dtick\":1,\"gridcolor\":\"rgb(0, 0, 0)\",\"side\":\"top\",\"ticks\":\"\"},\"yaxis\":{\"dtick\":1,\"ticks\":\"\",\"ticksuffix\":\"  \",\"autorange\":\"reversed\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"margin\":{\"t\":50,\"l\":200}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d77db4d7-d461-43f2-8063-808171e3efb4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optimizer=nadam\n",
        "epochs=10\n",
        "batch = 64\n",
        "eta=0.001\n",
        "alpha=0\n",
        "hidden_layer_size = 128\n",
        "hidden_layers = 5\n",
        "strat='xavier'\n",
        "act_fun ='relu'\n",
        "loss_fun='cross_entropy'\n",
        "hl = [hidden_layer_size]*hidden_layers\n",
        "ol = [len(train_y[0])]\n",
        "n_hl = len(hl)\n",
        "\n",
        "if optimizer==stochastic_gradient_descent:\n",
        "  W,b = stochastic_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==momentum_gradient_descent:\n",
        "  W,b = momentum_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==nesterov_gradient_descent:\n",
        "  W,b = nesterov_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==rmsprop:\n",
        "  W,b = rmsprop(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==adaptive_moments:\n",
        "  W,b = adaptive_moments(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==nadam:\n",
        "  W,b = nadam(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        " \n",
        "wandb.init(entity=\"cs22m035\", project=\"confusion\")\n",
        "# wandb.run.name = \"Q1\"\n",
        "# show_images(train_images , train_labels , labels)\n",
        "\n",
        "train_acc, train_loss,ytrue,ypred = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)  \n",
        "cmat = get_confusion_matrix(ytrue , ypred , labels , figsize=(20,20))\n",
        "\n",
        "wandb.log({\n",
        "          \"Confusion_Matrix\": cmat  \n",
        "        })"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
