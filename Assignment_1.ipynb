{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNNlw7Z-S965"
      },
      "source": [
        "#Assignment 1: Build FeedForward Neural Network Architecture \n",
        "\n",
        "The goal of this assignment is twofold: (i) implement and use gradient descent (and its variants) with\n",
        "backpropagation for a classification task (ii) get familiar with wandb which is a cool tool for running and keeping track of a large number of experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4QoUJr0THu3"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:04.785354Z",
          "iopub.status.busy": "2023-03-17T18:35:04.784944Z",
          "iopub.status.idle": "2023-03-17T18:35:17.158638Z",
          "shell.execute_reply": "2023-03-17T18:35:17.157173Z",
          "shell.execute_reply.started": "2023-03-17T18:35:04.785317Z"
        },
        "id": "_V3jTIQpTOyS",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-90fc07b79712>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from sklearn import metrics\n",
        "import random\n",
        "from keras.datasets import mnist\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.colors\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import log_loss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        " \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6_p5F27TRDy"
      },
      "source": [
        "### Installing and Login to Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:17.160988Z",
          "iopub.status.busy": "2023-03-17T18:35:17.160266Z",
          "iopub.status.idle": "2023-03-17T18:35:33.434003Z",
          "shell.execute_reply": "2023-03-17T18:35:33.432440Z",
          "shell.execute_reply.started": "2023-03-17T18:35:17.160948Z"
        },
        "id": "kE3b2hyRN6tC",
        "outputId": "70010c2a-52ac-4c86-a5e3-cdf9c53888a2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m035\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login(key = \"13ebf1b4a6b39617b6456bf8f57f55bb361759b2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:33.436253Z",
          "iopub.status.busy": "2023-03-17T18:35:33.435850Z",
          "iopub.status.idle": "2023-03-17T18:35:36.038963Z",
          "shell.execute_reply": "2023-03-17T18:35:36.037561Z",
          "shell.execute_reply.started": "2023-03-17T18:35:33.436213Z"
        },
        "id": "ayQLhGJoAwQv",
        "outputId": "0ee182ae-ee36-4f5a-9ddb-4904b865a4df",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "labels = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.043205Z",
          "iopub.status.busy": "2023-03-17T18:35:36.042812Z",
          "iopub.status.idle": "2023-03-17T18:35:36.052577Z",
          "shell.execute_reply": "2023-03-17T18:35:36.050961Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.043161Z"
        },
        "id": "-uSN_ZDMAw_q",
        "outputId": "3b7c90bb-b832-4a22-a282-d4d53bec30c6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "60000\n",
            "60000\n",
            "[9 0 0 ... 3 0 5]\n"
          ]
        }
      ],
      "source": [
        "# checking details of dataset\n",
        "print(train_images.shape)\n",
        "print(len(train_images))\n",
        "print(len(train_labels))\n",
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.055016Z",
          "iopub.status.busy": "2023-03-17T18:35:36.054547Z",
          "iopub.status.idle": "2023-03-17T18:35:36.064180Z",
          "shell.execute_reply": "2023-03-17T18:35:36.062605Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.054966Z"
        },
        "id": "x6h8FtxYBAAB",
        "outputId": "f09ad264-144d-4066-cbdc-fe537654eae6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60000 28 28\n"
          ]
        }
      ],
      "source": [
        "N , a , b = train_images.shape\n",
        "#Dimesion of each Datapoint will be a*b\n",
        "print(N,a,b)\n",
        "x = a*b\n",
        "d = x\n",
        "nl = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.067459Z",
          "iopub.status.busy": "2023-03-17T18:35:36.066735Z",
          "iopub.status.idle": "2023-03-17T18:35:36.770922Z",
          "shell.execute_reply": "2023-03-17T18:35:36.769540Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.067337Z"
        },
        "id": "pNmFx17BbCY9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "c = list(zip(train_images, train_labels))\n",
        "random.shuffle(c)\n",
        "\n",
        "labels = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "N , a , b = train_images.shape\n",
        "\n",
        "train_images, train_labels = zip(*c)\n",
        "train_images = np.array(train_images) \n",
        "train_labels = np.array(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.773667Z",
          "iopub.status.busy": "2023-03-17T18:35:36.773164Z",
          "iopub.status.idle": "2023-03-17T18:35:36.779889Z",
          "shell.execute_reply": "2023-03-17T18:35:36.778716Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.773616Z"
        },
        "id": "_uzxa_ShHd7U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# wandb.init(project=\"Assignment 1\",name=\"Question 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l39O5G0LLouw"
      },
      "source": [
        "#Question 1\n",
        "Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid below. Use from keras.datasets import fashion_mnist for getting the fashion mnist dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.782740Z",
          "iopub.status.busy": "2023-03-17T18:35:36.782291Z",
          "iopub.status.idle": "2023-03-17T18:35:36.792670Z",
          "shell.execute_reply": "2023-03-17T18:35:36.791132Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.782698Z"
        },
        "id": "1DDfpoyEVbND",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def show_images(train_images , train_labels , desc):\n",
        "  \n",
        "    fig, axs = plt.subplots(2, 5, figsize=(12, 6))\n",
        "    axs = axs.flatten()\n",
        "    class_images=[]\n",
        "\n",
        "    for i in range(10):\n",
        "          index=np.argmax(train_labels==i)\n",
        "          # Plot the image\n",
        "          axs[i].imshow(train_images[index], cmap='gray')\n",
        "          axs[i].set_title(labels[i])\n",
        "          axs[i].axis('off')\n",
        "          image = wandb.Image(train_images[index], caption=labels[i])\n",
        "          class_images.append(image)\n",
        "\n",
        "    wandb.log({\"examples\": class_images})\n",
        "    \n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIDREPHNHRWh"
      },
      "source": [
        "# Question 2 (10 Marks)\n",
        "Implement a feedforward neural network which takes images from the fashion-mnist data as input and outputs a probability distribution over the 10 classes.\n",
        "\n",
        "Your code should be flexible such that it is easy to change the number of hidden layers and the number of neurons in each hidden layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkCkYjcLLusM"
      },
      "source": [
        "###Propecessing of data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:36.794640Z",
          "iopub.status.busy": "2023-03-17T18:35:36.794264Z",
          "iopub.status.idle": "2023-03-17T18:35:37.008394Z",
          "shell.execute_reply": "2023-03-17T18:35:37.006996Z",
          "shell.execute_reply.started": "2023-03-17T18:35:36.794606Z"
        },
        "id": "zJ2nvR4fdIdz",
        "outputId": "fe10c1d9-e594-4b44-e278-3e8bbacae58c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "Shape of flattened_train_images is :  (60000, 784)\n",
            "Shape of flattened_test_images is  :  (10000, 784)\n"
          ]
        }
      ],
      "source": [
        "#Flattening we are converting the 28*28 data point as 784*1 data point\n",
        "print(train_images.shape)\n",
        "\n",
        "flattened_images = []\n",
        "for i in range(len(train_images)):\n",
        "    flattened_image = train_images[i].flatten()\n",
        "    flattened_images.append(flattened_image)\n",
        "flatted_train_images = np.array(flattened_images)\n",
        "\n",
        "print(\"Shape of flattened_train_images is : \",flatted_train_images.shape)\n",
        "\n",
        "  \n",
        "#Same transition for testdata\n",
        "flattened_images = []\n",
        "for i in range(len(test_images)):\n",
        "    flattened_image = test_images[i].flatten()\n",
        "    flattened_images.append(flattened_image)\n",
        "flatted_test_images = np.array(flattened_images)\n",
        "print(\"Shape of flattened_test_images is  : \",flatted_test_images.shape)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.009879Z",
          "iopub.status.busy": "2023-03-17T18:35:37.009543Z",
          "iopub.status.idle": "2023-03-17T18:35:37.071251Z",
          "shell.execute_reply": "2023-03-17T18:35:37.069593Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.009847Z"
        },
        "id": "uC7nrfY8WEWB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#getting train data and validation data from training data\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, valid_x, cat_train_y, cat_val_y = train_test_split(flatted_train_images, train_labels, test_size=0.1, stratify = train_labels ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.073426Z",
          "iopub.status.busy": "2023-03-17T18:35:37.072929Z",
          "iopub.status.idle": "2023-03-17T18:35:37.114751Z",
          "shell.execute_reply": "2023-03-17T18:35:37.113505Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.073387Z"
        },
        "id": "tOnDidLOiujh",
        "outputId": "e40c4339-614f-4588-b8b8-e94bbc724c54",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(54000, 10)\n",
            "(6000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "source": [
        "#One hot encoding of categorical labels \n",
        "def encode(data, nl):\n",
        "    encode_data = np.zeros((len(data), nl))\n",
        "    for i in range(len(data)):\n",
        "        actual_label = data[i]\n",
        "        encode_data[i][actual_label] = 1\n",
        "    return encode_data\n",
        "\n",
        "\n",
        "#One hot ecoding \n",
        "train_y = encode(cat_train_y , nl)\n",
        "print(train_y.shape)\n",
        "valid_y = encode(cat_val_y , nl)\n",
        "print(valid_y.shape)\n",
        "test_y = encode(test_labels , nl)\n",
        "print(test_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.116582Z",
          "iopub.status.busy": "2023-03-17T18:35:37.116236Z",
          "iopub.status.idle": "2023-03-17T18:35:37.437947Z",
          "shell.execute_reply": "2023-03-17T18:35:37.436614Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.116550Z"
        },
        "id": "4gB5g1rbiuoh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Normalizing the data\n",
        "mean = np.mean(train_x , axis = 0)\n",
        "train_x = (train_x - mean) /255\n",
        "test_x = (flatted_test_images - mean)/255\n",
        "valid_x = (valid_x - mean)/255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nr5kCu-plvfi"
      },
      "outputs": [],
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfc75empL3_4"
      },
      "source": [
        "#Activation functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.446130Z",
          "iopub.status.busy": "2023-03-17T18:35:37.445686Z",
          "iopub.status.idle": "2023-03-17T18:35:37.459778Z",
          "shell.execute_reply": "2023-03-17T18:35:37.458460Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.446088Z"
        },
        "id": "Nb8lRFqmSSY5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Sigmoid \n",
        " \n",
        "def sigmoid(x):\n",
        "    temp = []\n",
        "    # exp_xi=[]\n",
        "    for i in range(len(x)):\n",
        "        # exp_xi=np.exp(-float(x[i]))\n",
        "        result = (1/(1 + np.exp(-(float(x[i])))))\n",
        "        temp.append(result)\n",
        "    return np.array(temp)\n",
        "#Tanh\n",
        "def tanh(x):\n",
        "    temp = []\n",
        "    for i in range(len(x)):\n",
        "      result=np.tanh(x[i])\n",
        "      temp.append(result)\n",
        "\n",
        "    return np.array(temp)\n",
        "#ReLU\n",
        "def relu(x):\n",
        "    temp = []\n",
        "    for i in range(len(x)):\n",
        "      if x[i]>0:\n",
        "        temp.append(x[i])\n",
        "      elif x[i]<=0:\n",
        "        temp.append(0)\n",
        "    return np.array(temp)\n",
        "    \n",
        "#Softmax\n",
        "def softmax(x):\n",
        "  \n",
        "  sum=0\n",
        "  for i in range(len(x)):\n",
        "    sum+=np.exp(float(x[i]))\n",
        "  temp=[]  \n",
        "  for i in range(len(x)):\n",
        "    result=np.exp(float(x[i]))\n",
        "    temp.append(result/sum)\n",
        "\n",
        "  return np.array(temp)\n",
        "\n",
        "#Derivative of Sigmoid\n",
        "def derivative_sigmoid(x):\n",
        "    temp=x*(1 - x)\n",
        "    return temp\n",
        "\n",
        "#Derivative of Tanh\n",
        "def derivative_tanh(x):\n",
        "    cal_tanh=1-np.square(x)\n",
        "    return cal_tanh\n",
        "\n",
        "#Derivative of ReLU\n",
        "def derivative_relu(x):\n",
        "    temp = []\n",
        "    sum=0\n",
        "    for i in range(len(x)):\n",
        "      if x[i]<=0:\n",
        "        temp.append(0)\n",
        "      elif x[i]>0:\n",
        "        temp.append(1)\n",
        "    return np.array(temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ-tlLaeMLtI"
      },
      "source": [
        "#Network initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.461412Z",
          "iopub.status.busy": "2023-03-17T18:35:37.461088Z",
          "iopub.status.idle": "2023-03-17T18:35:37.473393Z",
          "shell.execute_reply": "2023-03-17T18:35:37.471947Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.461383Z"
        },
        "id": "yO6X3QBoMxae",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "def intitialize_zero_input(dim, hl, ol,w,b,d):\n",
        "\n",
        "    for i in range(len(hl)):\n",
        "        hl_size=hl[i]\n",
        "        b.append(np.zeros(hl_size))\n",
        "       \n",
        "        if i == 0:\n",
        "            \n",
        "            w.append(np.zeros((hl_size, d)))\n",
        "        else:\n",
        "            lst_size=hl[i-1]\n",
        "            w.append(np.zeros((hl_size,lst_size )))\n",
        "    return w,b\n",
        "\n",
        "def initialize_zero_output(im, hl, ol,w,b,d):\n",
        "\n",
        "    for i in range(len(ol)):\n",
        "        ol_size=ol[i]\n",
        "        b.append(np.zeros(ol_size))\n",
        "        w.append(np.zeros((ol_size, hl[-1])))\n",
        "    return w,b\n",
        "\n",
        "\n",
        "def initialize_zeros(dim, hl, ol):\n",
        "    w = [np.array([])]\n",
        "    b = [np.array([])]\n",
        "    d = dim\n",
        "  \n",
        "    w,b=intitialize_zero_input(dim, hl, ol,w,b,d)\n",
        "    w,b=initialize_zero_output(dim, hl, ol,w,b,d)\n",
        "\n",
        "    return w, b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq38vwJxHi7u"
      },
      "source": [
        "### Random Initialization And Xavier Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.475489Z",
          "iopub.status.busy": "2023-03-17T18:35:37.475137Z",
          "iopub.status.idle": "2023-03-17T18:35:37.494767Z",
          "shell.execute_reply": "2023-03-17T18:35:37.493341Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.475456Z"
        },
        "id": "5Anplb6Dlvh-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def intitialize_random_input(dim, hl, ol,W,b,d):\n",
        "    np.random.seed(2)\n",
        "\n",
        "    for i in range(len(hl)):\n",
        "        hd_size=hl[i]\n",
        "        b.append(np.random.randn(hd_size))\n",
        "        if(i == 0):\n",
        "          W.append(np.random.randn(hd_size,dim))\n",
        "        else:\n",
        "          lst_size=hl[i - 1]\n",
        "          W.append(np.random.randn(hd_size,lst_size))\n",
        "\n",
        "    return W,b\n",
        "\n",
        "def initialize_random_output(im, hl, ol,W,b,d):\n",
        "\n",
        "    np.random.seed(2)\n",
        "    for i in range(len(ol)):\n",
        "        ol_size=ol[i]\n",
        "        lst_hl_size=hl[-1]\n",
        "        b.append(np.random.randn(ol_size))\n",
        "        W.append(np.random.randn(ol_size,lst_hl_size))\n",
        "    return W,b\n",
        "\n",
        "def random_initialization(dim, hl, ol,W,b,d):\n",
        "   \n",
        "  \n",
        "    W,b=intitialize_random_input(dim, hl, ol,W,b,d)\n",
        "    W,b=initialize_random_output(dim, hl, ol,W,b,d)\n",
        "\n",
        "    return W,b\n",
        "\n",
        "def intitialize_xavier_input(dim, hl, ol,W,b,d):\n",
        "    np.random.seed(2)\n",
        "\n",
        "    for i in range(len(hl)):\n",
        "        hl_size=hl[i]\n",
        "        b.append( np.random.randn(hl_size))\n",
        "        if (i == 0):\n",
        "            W.append(np.random.randn(hl_size,dim ) * np.sqrt(1/dim))\n",
        "        else:\n",
        "            lst_hd_size=hl[i-1]\n",
        "            W.append(np.random.randn(hl_size,lst_hd_size) * np.sqrt(1/lst_hd_size))\n",
        "    return W,b     \n",
        "\n",
        "def initialize_xavier_output(im, hl, ol,W,b,d):\n",
        "    np.random.seed(2)\n",
        "    for i in range(len(ol)):\n",
        "        ol_size=ol[i]\n",
        "        b.append(np.random.randn(ol_size))\n",
        "        lst_ol=hl[-1]\n",
        "        W.append(np.random.randn(ol_size, lst_ol)* np.sqrt(1/lst_ol))\n",
        "    return W,b\n",
        "\n",
        "def xavier_initialization(dim, hl, ol,W,b,d):\n",
        "   \n",
        "  \n",
        "    W,b=intitialize_xavier_input(dim, hl, ol,W,b,d)\n",
        "    W,b=initialize_xavier_output(dim, hl, ol,W,b,d)\n",
        "\n",
        "    return  W,b\n",
        "\n",
        "#Initialize Network \n",
        "def initialize_network(dim, hl, ol, method):\n",
        "  np.random.seed(2)\n",
        "  # Declaring 2d numpy array\n",
        "  W = [np.array([])]\n",
        "  b = [np.array([])]\n",
        " \n",
        "  d = dim\n",
        "  #Setting up the random seed\n",
        "  \n",
        "\n",
        "  #Random Intialization\n",
        "  if(method=='random'):\n",
        "     W,b=random_initialization(dim,hl,ol,W,b,d)\n",
        "      \n",
        "  #Xavier Initialization\n",
        "  else:\n",
        "     W,b= xavier_initialization(dim,hl,ol,W,b,d)\n",
        "\n",
        "  return W,b\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y7VQGKpMQXO"
      },
      "source": [
        "#Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.496906Z",
          "iopub.status.busy": "2023-03-17T18:35:37.496565Z",
          "iopub.status.idle": "2023-03-17T18:35:37.514877Z",
          "shell.execute_reply": "2023-03-17T18:35:37.513714Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.496875Z"
        },
        "id": "yHRXzM_ysJua",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        "def sigmoid_method(w,b,x,a,c,d,h):\n",
        "  num_layers = (len(w)-1)\n",
        "  for i in range(1 , num_layers):\n",
        "            wh=np.dot( w[i], h[i-1] )\n",
        "            c = wh + b[i]\n",
        "            a.append(c)\n",
        "            d = sigmoid(c)\n",
        "            h.append(d)\n",
        "def tanh_method(w,b,x,a,c,d,h):\n",
        "  num_layers = (len(w)-1)\n",
        "  for i in range(1 , num_layers):\n",
        "            c = (w[i]@h[i-1])+b[i]\n",
        "            a.append(c)\n",
        "            h.append(tanh(c))\n",
        "            \n",
        "def identity_method(w,b,x,a,c,d,h):\n",
        "  num_layers = (len(w)-1)\n",
        "  for i in range(1 , num_layers):\n",
        "            c = (w[i]@h[i-1])+b[i]\n",
        "            a.append(c)\n",
        "            h.append(c)\n",
        "\n",
        "\n",
        "def relu_method(w,b,x,a,c,d,h):\n",
        "  num_layers = (len(w)-1)\n",
        "  for i in range(1 , num_layers):\n",
        "            c = (w[i]@h[i-1])+b[i]            \n",
        "            a.append(c)\n",
        "            h.append(relu(c))\n",
        "\n",
        "#Forward Propagation Framework\n",
        "def forward_propagation(w,b,x,method='sigmoid'):\n",
        "    a = [[]]\n",
        "    h = [[]]\n",
        "    # inserting data into first layer\n",
        "    h[0] = x\n",
        "    hl_size=(len(w)-1)\n",
        "    num_layers = hl_size\n",
        "    c = []\n",
        "    d = []\n",
        "    #Sigmoid as activation function in every hidden layer\n",
        "    if method=='sigmoid':\n",
        "        sigmoid_method(w,b,x,a,c,d,h)\n",
        "    #Tanh as activation function in every hidden layer\n",
        "    elif method=='tanh':\n",
        "        tanh_method(w,b,x,a,c,d,h)\n",
        "    #ReLU as activation function in every hidden layer\n",
        "    elif method=='relu':\n",
        "       relu_method(w,b,x,a,c,d,h)\n",
        "    elif method == \"identity\":\n",
        "        identity_method(w,b,x,a,c,d,h)\n",
        "    #Softmax at output Layer\n",
        "    c = w[num_layers] @ h[num_layers-1] + b[num_layers]\n",
        "    d = softmax(c)\n",
        "    a.append(c)\n",
        "    h.append(d)\n",
        "    \n",
        "\n",
        "    return a,h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l1OXNypMUSf"
      },
      "source": [
        "#Backward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.517756Z",
          "iopub.status.busy": "2023-03-17T18:35:37.516585Z",
          "iopub.status.idle": "2023-03-17T18:35:37.532919Z",
          "shell.execute_reply": "2023-03-17T18:35:37.531428Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.517708Z"
        },
        "id": "fTdgFIC4sbnI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "# Loss function cross entropy\n",
        "def cross_entropy_loss_fun(y_pred,y):\n",
        "  cr=y_pred-y\n",
        "  return cr\n",
        "\n",
        "# Loss squared error\n",
        "def sqrd_error_loss_fun(y_pred,y):\n",
        "  y_label = y_pred[np.argmax(y)]\n",
        "  res= 2 * (y_label - 1) * y_label * ( y - y_pred )\n",
        "  return res\n",
        "\n",
        " \n",
        "#Backpropagation Framework\n",
        "def back_prop(W,h,x,y,y_pred,act_fun,loss_fun):\n",
        "  del_W=[[]]\n",
        "  del_b=[[]]\n",
        "\n",
        "  #Computing output grad wrt Cross Entropy Loss function\n",
        "  if loss_fun == \"cross_entropy\" :\n",
        " \n",
        "    del_a = cross_entropy_loss_fun(y_pred,y)\n",
        "    \n",
        "    \n",
        "  #Computing output grad wrt Squared Error Loss function\n",
        "  else:\n",
        " \n",
        "    del_a=sqrd_error_loss_fun(y_pred,y)\n",
        "\n",
        "  for i in range(len(W)-1, 0, -1):\n",
        "\n",
        "    #computing gradients wrt parameters W,b\n",
        "    \n",
        "    db = np.array( del_a )\n",
        "    dot_prod = np.dot(np.matrix(del_a).T , np.matrix(h[i-1]))\n",
        "    dW = np.array(dot_prod)\n",
        "    \n",
        "\n",
        "    #computing gradients wrt below layer activation function\n",
        "    dh = np.dot( np.transpose(W[i]), del_a )\n",
        "\n",
        "    #computing gradients wrt below layer pre-activation function\n",
        "    if act_fun == \"sigmoid\":\n",
        "      del_a = dh *  h[i-1] * (1 - h[i-1])\n",
        "    \n",
        "    elif act_fun == \"tanh\":\n",
        "      del_a = dh * (1 - h[i-1]**2)\n",
        "    \n",
        "    elif act_fun == \"relu\":\n",
        "      del_a = dh * (h[i-1] > 0)\n",
        "    elif act_fun == \"identity\":\n",
        "        pass\n",
        "\n",
        "    del_W.insert(1, dW)\n",
        "    del_b.insert(1, db)\n",
        "\n",
        "  return del_W, del_b\n",
        "\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im9PeUfFHseQ"
      },
      "source": [
        "# Question 3 (24 Marks)\n",
        "Implement the backpropagation algorithm with support for the following optimisation functions\n",
        "\n",
        "* sgd\n",
        "* momentum based gradient descent\n",
        "* nesterov accelerated gradient descent\n",
        "* rmsprop\n",
        "* adam\n",
        "* nadam\n",
        "\n",
        "(12 marks for the backpropagation framework and 2 marks for each of the optimisation algorithms above)\n",
        "\n",
        "We will check the code for implementation and ease of use (e.g., how easy it is to add a new optimisation algorithm such as Eve). Note that the code should be flexible enough to work with different batch sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXprOTMuMaQ1"
      },
      "source": [
        "#Stochastic Gradient Descent optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_8yKZRTH0_0"
      },
      "source": [
        "#### Printing errors and Logging data in Wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.534865Z",
          "iopub.status.busy": "2023-03-17T18:35:37.534430Z",
          "iopub.status.idle": "2023-03-17T18:35:37.550362Z",
          "shell.execute_reply": "2023-03-17T18:35:37.548765Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.534816Z"
        },
        "id": "-A44hpFluYZP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun):\n",
        "\n",
        "    print(\"epoch:\" , e+1 , \" \"+loss_fun+\" \", \"train_acc :\" , train_acc , \"valid_acc :\" , val_acc , \"test_acc :\" , test_acc)\n",
        "    \n",
        "    if loss_fun==\"cross_entropy\":\n",
        "      wandb.log({\n",
        "          \"Epoch\": e+1,\n",
        "          \"Train Loss\": train_loss,\n",
        "          \"Train Acc\": train_acc*100,\n",
        "          \"Valid Loss\": val_loss,\n",
        "          \"Valid Acc\": val_acc*100})\n",
        "    else:\n",
        "      wandb.log({\n",
        "          \"Train Loss (squared_error)\": train_loss,\n",
        "          \"Train Acc (squared_error)\": train_acc*100,\n",
        "          \"Valid Loss (squared_error)\": val_loss,\n",
        "          \"Valid Acc (squared_error)\": val_acc*100})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.552882Z",
          "iopub.status.busy": "2023-03-17T18:35:37.552366Z",
          "iopub.status.idle": "2023-03-17T18:35:37.571528Z",
          "shell.execute_reply": "2023-03-17T18:35:37.569971Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.552827Z"
        },
        "id": "b4B_B7zxsbpx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        "def update_dw_db(tdw,tdb,dw,db):\n",
        "    for i in range(len(tdw)):\n",
        "        dw[i] += tdw[i]\n",
        "        db[i] += tdb[i]\n",
        "    return dw,db\n",
        "   \n",
        "def stochastic_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function implements the Stochastic Gradient Descent (SGD) algorithm for training\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      train_x: Input data for training\n",
        "      train_y: labels for training data\n",
        "      valid_x: Input data for validation\n",
        "      valid_y: labels for validation data\n",
        "      d: List containing the number of neurons in the input layer and each hidden layer\n",
        "      hl: Number of hidden layers\n",
        "      ol: Number of neurons in the output layer\n",
        "      act_fun: Activation function used in the hidden layers\n",
        "      loss_fun: Loss function used in the output layer\n",
        "      epochs: Number of epochs to train the network\n",
        "      eta: Learning rate\n",
        "      strat: Weight initialization strategy\n",
        "      alpha: Parameter for momentum-based optimization\n",
        "      batch: Batch size\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "      w: List of weight matrices for each layer after training\n",
        "      b: List of bias vectors for each layer after training\n",
        "\n",
        "  \"\"\"  \n",
        "  \n",
        "  size_image=784\n",
        "  #Initializing the weights and biases based on given strategy\n",
        "  w,b = initialize_network(d, hl, ol, strat)\n",
        "  counter=0\n",
        " \n",
        "  dw , db = initialize_zeros(size_image,hl,ol)\n",
        "\n",
        "  seen = 0\n",
        "  for e in range(epochs):\n",
        "    counter+=1\n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "\n",
        "      a,h = forward_propagation(w, b, x, act_fun)\n",
        "      last_ele=len(h)-1\n",
        "      y_pred=h[last_ele]\n",
        "      seen += 1\n",
        "     \n",
        "      tdw,tdb=back_prop(w, h, x, y, y_pred, act_fun, loss_fun)\n",
        "\n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "\n",
        "      if(seen==batch or it==len(train_x)-1):\n",
        "        seen = 0\n",
        "        for i in range(len(w)):\n",
        "            weight=w[i]\n",
        "            deriv=dw[i]\n",
        "            # w[i] = weight - eta * np.array(deriv)\n",
        "            w[i] = weight - eta * np.array(deriv) - eta*alpha*weight\n",
        "\n",
        "        for i in range(len(b)):\n",
        "            bias=b[i]\n",
        "            deriv=db[i]\n",
        "            b[i] = bias - eta * np.array(deriv) - eta*alpha*bias\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    #Getting train,val,test accuracies and losses and predictions with true labels\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(w, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(w, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(w, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "   \n",
        "  return w,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7JpBnmAMhNU"
      },
      "source": [
        "#Momentum Based Gradient Descent "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.573601Z",
          "iopub.status.busy": "2023-03-17T18:35:37.573169Z",
          "iopub.status.idle": "2023-03-17T18:35:37.592182Z",
          "shell.execute_reply": "2023-03-17T18:35:37.590617Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.573562Z"
        },
        "id": "wYT8Ed0eVIwu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        "\n",
        " \n",
        "def momentum_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function performs momentum gradient descent to optimize the weights and biases of a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      gamma: Gamma value for the optimizer\n",
        "      eta: learning rate\n",
        "      strat: weight initialization strategy\n",
        "      alpha: momentum hyperparameter\n",
        "      \n",
        "  \"\"\"\n",
        "\n",
        "  gamma=0.9\n",
        "  seen=0\n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "  counter=0\n",
        "  dw , db = initialize_zeros(784,hl,ol)\n",
        "  prev_w , prev_b = initialize_zeros(784,hl,ol)\n",
        "  for e in range(epochs):\n",
        "    counter+=1\n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      seen+=1\n",
        "      a,h = forward_propagation(W, b, x, act_fun)\n",
        "      y_pred=h[len(h)-1]\n",
        "      \n",
        "      tdw,tdb=back_prop(W, h, x, y, y_pred, act_fun, loss_fun)\n",
        "  \n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "    \n",
        "      if(seen==batch or it==len(train_x)-1):\n",
        "        seen=0\n",
        "        for i in range(len(W)):\n",
        "            weight = W[i]\n",
        "            deriv = dw[i]\n",
        "            new_weight = weight - eta * np.array(deriv) - gamma * prev_w[i]- eta*alpha*weight\n",
        "            new_prev_w = eta * np.array(deriv) + gamma * prev_w[i]\n",
        "            W[i] = new_weight\n",
        "            prev_w[i] = new_prev_w\n",
        "\n",
        "\n",
        "        for i in range(len(b)):\n",
        "            bias = b[i]\n",
        "            deriv = db[i]\n",
        "            new_bias = bias - eta * np.array(deriv) - gamma * prev_b[i] - eta*alpha*bias\n",
        "            new_prev_b = eta * np.array(deriv) + gamma * prev_b[i]\n",
        "            b[i] = new_bias\n",
        "            prev_b[i] = new_prev_b\n",
        "            \n",
        "            dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybb-fTh2MlKf"
      },
      "source": [
        "#Nesterov Accelerated Gradient Descent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.594713Z",
          "iopub.status.busy": "2023-03-17T18:35:37.594211Z",
          "iopub.status.idle": "2023-03-17T18:35:37.615232Z",
          "shell.execute_reply": "2023-03-17T18:35:37.614092Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.594662Z"
        },
        "id": "WOFtP3b3r6lo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def cal_v_w_v_b(W,v_w,v_b,gamma,prev_w,prev_b):\n",
        "    for i in range(len(W)):\n",
        "        v_w[i] = gamma*prev_w[i]\n",
        "        v_b[i] = gamma*prev_b[i]\n",
        "    return v_w,v_b\n",
        "    \n",
        "def cal_t_w_t_b(W,tw,tb,v_w,v_b,b):\n",
        "    for i in range(len(W)):\n",
        "        tw[i] = W[i] - v_w[i]\n",
        "        tb[i] = b[i] - v_b[i]\n",
        "    return tw,tb\n",
        "\n",
        "def nesterov_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function performs nesterov gradient descent to optimize the weights and biases of a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      gamma: Gamma value for the optimizer\n",
        "      eta: learning rate\n",
        "      strat: weight initialization strategy\n",
        "      alpha: momentum hyperparameter\n",
        "      \n",
        "  \"\"\" \n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "\n",
        "  gamma=0.9\n",
        "  seen=0\n",
        "  \n",
        "  prev_w , prev_b = initialize_zeros(784,hl,ol)\n",
        "  v_w , v_b =initialize_zeros(784,hl,ol)\n",
        "\n",
        "  dw , db = initialize_zeros(784,hl,ol)\n",
        "  tw , tb = initialize_zeros(784,hl,ol)\n",
        "\n",
        "  for e in range(epochs):\n",
        "\n",
        "     \n",
        "    v_w,v_b = cal_v_w_v_b(W,v_w,v_b,gamma,prev_w,prev_b)\n",
        "    \n",
        "    tw,tb = cal_t_w_t_b(W,tw,tb,v_w,v_b,b)\n",
        "     \n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      a,h = forward_propagation(tw, tb, x, act_fun)\n",
        "      hl_size=len(h)-1\n",
        "      y_pred=h[hl_size]\n",
        "      seen+=1\n",
        "      tdw,tdb=back_prop(tw, h, x, y, y_pred, act_fun, loss_fun)\n",
        "      \n",
        "      update_dw_db(tdw,tdb,dw,db)\n",
        "\n",
        "      if seen==batch or it == len(train_x)-1:\n",
        "        seen=0\n",
        "        for i in range(len(W)):\n",
        "          weight = W[i]\n",
        "          deriv = dw[i]\n",
        "          v_w[i] = gamma*prev_w[i] + eta*np.array(deriv) - eta*alpha*weight\n",
        "          W[i] = weight - v_w[i]\n",
        "          tw[i] = W[i]\n",
        "          prev_w = v_w\n",
        "\n",
        "        for i in range(len(b)):\n",
        "          bias = b[i]\n",
        "          deriv = db[i]\n",
        "          v_b[i] = gamma*prev_b[i] + eta*np.array(deriv)- eta*alpha*bias\n",
        "          b[i] = bias - v_b[i]\n",
        "          tb[i] = b[i]\n",
        "          prev_b = v_b\n",
        "\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRsDnJLyM7xm"
      },
      "source": [
        "#RMS_Prop Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.618766Z",
          "iopub.status.busy": "2023-03-17T18:35:37.617111Z",
          "iopub.status.idle": "2023-03-17T18:35:37.637237Z",
          "shell.execute_reply": "2023-03-17T18:35:37.635658Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.618694Z"
        },
        "id": "iCF8hfEfZrRo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def rmsprop(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch,beta = 0.9):\n",
        "  \"\"\"\n",
        "    This function performs Root Mean Square Propagation (RMSprop)  to optimize the weights and biases of a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      gamma: Gamma value for the optimizer\n",
        "      beta : exponential decay rate\n",
        "      eta: learning rate\n",
        "      strat: weight initialization strategy\n",
        "      alpha: momentum hyperparameter\n",
        "      \n",
        "  \"\"\" \n",
        "  prev_w , prev_b = initialize_zeros(784,hl,ol)\n",
        "  eps = 1e-8 \n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "  seen=0\n",
        "  \n",
        "  prev_w , prev_b = initialize_zeros(784,hl,ol)\n",
        "  dw , db = initialize_zeros(784,hl,ol)\n",
        "   \n",
        "\n",
        "  for e in range(epochs):\n",
        "  \n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      \n",
        "      a,h = forward_propagation(W, b, x, act_fun)\n",
        "      hl_size=len(h)-1\n",
        "      y_pred=h[hl_size]\n",
        "      seen+=1\n",
        "      tdw,tdb=back_prop(W, h, x, y, y_pred, act_fun, loss_fun)\n",
        "      \n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "      \n",
        "      if seen==batch or it == len(train_x)-1:\n",
        "\n",
        "        seen=0\n",
        "        for i, (dw_i, db_i) in enumerate(zip(dw,db)):\n",
        "          prev_w[i] = beta*prev_w[i] + (1-beta)*(dw_i**2)\n",
        "          prev_b[i] = beta*prev_b[i] + (1-beta)*(db_i**2)\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          weight=W[i]\n",
        "          deriv=dw[i]\n",
        "          W[i] = weight - (eta / np.sqrt(prev_w[i] + eps)) * np.array(deriv) - eta*alpha*weight\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          bias=b[i]\n",
        "          deriv=db[i]\n",
        "          b[i] = bias - (eta / np.sqrt(prev_b[i] + eps)) * np.array(deriv) - eta*alpha*bias\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIlcCzcJNOdq"
      },
      "source": [
        "#Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.640021Z",
          "iopub.status.busy": "2023-03-17T18:35:37.639235Z",
          "iopub.status.idle": "2023-03-17T18:35:37.662312Z",
          "shell.execute_reply": "2023-03-17T18:35:37.660815Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.639976Z"
        },
        "id": "qpjZJAhk47Sy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def adaptive_moments(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function implements the Adaptive Moments (Adam) optimization algorithm for training a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      beta1, beta2 : exponential decay rate\n",
        "      strat: weight initialization strategy\n",
        "     \n",
        "  \"\"\"\n",
        "  dimention=784\n",
        "  dw , db = initialize_zeros(dimention,hl,ol)\n",
        "  m_w , m_b = initialize_zeros(dimention,hl,ol)\n",
        "  eps=1e-8\n",
        "  v_w , v_b = initialize_zeros(dimention,hl,ol)\n",
        "  beta1 , beta2 =  0.9 , 0.99\n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "  m_w_hat , m_b_hat = initialize_zeros(dimention,hl,ol)\n",
        "  v_w_hat , v_b_hat = initialize_zeros(dimention,hl,ol)\n",
        "  seen=0\n",
        "  c=0\n",
        "\n",
        "  for e in range(epochs):\n",
        "  \n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      \n",
        "      a,h = forward_propagation(W, b, x, act_fun)\n",
        "      hl_size=len(h)-1\n",
        "      y_pred=h[hl_size]\n",
        "      seen+=1\n",
        "\n",
        "      tdw,tdb=back_prop(W, h, x, y, y_pred, act_fun, loss_fun)\n",
        "      \n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "\n",
        "      if seen==batch or it == len(train_x)-1:\n",
        "\n",
        "        seen=0\n",
        "        c+=1\n",
        "        for i in range(len(W)):\n",
        "          dw_i=dw[i]\n",
        "          db_i=db[i]\n",
        "          m_w[i] = beta1 * m_w[i] + (1 - beta1) * dw_i\n",
        "          m_b[i] = beta1 * m_b[i] + (1 - beta1) * db_i\n",
        "          v_w[i] = beta2 * v_w[i] + (1 - beta2) * dw_i ** 2\n",
        "          v_b[i] = beta2 * v_b[i] + (1 - beta2) * db_i ** 2\n",
        "\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          denom1=(1 - np.power(beta1,c))\n",
        "          denom2=(1 - np.power(beta2,c))\n",
        "\n",
        "          m_w_hat[i] = m_w[i] / denom1\n",
        "          m_b_hat[i] = m_b[i] / denom1\n",
        "\n",
        "          v_w_hat[i] = v_w[i] / denom2\n",
        "          v_b_hat[i] = v_b[i] / denom2\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          weight=W[i]\n",
        "          deriv=dw[i]\n",
        "          W[i] = weight - (eta / np.sqrt(v_w_hat[i] + eps)) * m_w_hat[i] - eta*alpha*weight\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          bias=b[i]\n",
        "          deriv=db[i]\n",
        "          b[i] = bias - (eta / np.sqrt(v_b_hat[i] + eps)) * m_b_hat[i] - eta*alpha*bias\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfDrDkl0NTfM"
      },
      "source": [
        "#Nadam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.667067Z",
          "iopub.status.busy": "2023-03-17T18:35:37.665668Z",
          "iopub.status.idle": "2023-03-17T18:35:37.688680Z",
          "shell.execute_reply": "2023-03-17T18:35:37.687603Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.666982Z"
        },
        "id": "dScKlrVAMjHu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def nadam(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch):\n",
        "  \"\"\"\n",
        "    This function implements the Nesterov-accelerated Adaptive Moment  (NAdam) optimization algorithm for training a neural network.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "      beta1, beta2 : exponential decay rates\n",
        "      strat: weight initialization strategy\n",
        "     \n",
        "  \"\"\"\n",
        "  dimention=784\n",
        "  eps=1e-8 \n",
        "  beta1 , beta2 =  0.9 , 0.99\n",
        "  W,b=initialize_network(d, hl, ol, strat)\n",
        "  dw , db = initialize_zeros(dimention,hl,ol)\n",
        "  m_w , m_b = initialize_zeros(dimention,hl,ol)\n",
        "  v_w , v_b = initialize_zeros(dimention,hl,ol)\n",
        " \n",
        "  m_w_hat , m_b_hat = initialize_zeros(dimention,hl,ol)\n",
        "  v_w_hat , v_b_hat = initialize_zeros(dimention,hl,ol)\n",
        "  seen=0\n",
        "  c=0\n",
        "\n",
        "  for e in range(epochs):\n",
        "  \n",
        "    for it, (x, y) in enumerate(zip(train_x, train_y)):\n",
        "      \n",
        "      a,h = forward_propagation(W, b, x, act_fun)\n",
        "      y_pred=h[len(h)-1]\n",
        "      \n",
        "      tdw,tdb=back_prop(W, h, x, y, y_pred, act_fun, loss_fun)\n",
        "      \n",
        "      dw,db=update_dw_db(tdw,tdb,dw,db)\n",
        "      seen+=1\n",
        "      if seen==batch or it == len(train_x)-1:\n",
        "\n",
        "        seen=0\n",
        "        c+=1\n",
        "        for i, (dw_i, db_i) in enumerate(zip(dw, db)):\n",
        "          m_w[i] = beta1 * m_w[i] + (1-beta1) * dw_i\n",
        "          m_b[i] = beta1 * m_b[i] + (1-beta1) * db_i\n",
        "\n",
        "          v_w[i] = beta2 * v_w[i] + (1-beta2) * (dw_i**2)\n",
        "          v_b[i] = beta2 * v_b[i] + (1-beta2) * (db_i**2)\n",
        "\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          denom1=(1 - np.power(beta1,c))\n",
        "          denom2=(1 - np.power(beta2,c))\n",
        "\n",
        "          m_w_hat[i] = ( (beta1 * m_w[i]) + ( (1 - beta1) * dw[i] ) )/ denom1\n",
        "          m_b_hat[i] = ( (beta1 * m_b[i]) + ( (1 - beta1) * db[i] ) )/ denom1\n",
        "\n",
        "          v_w_hat[i] = v_w[i] / denom2\n",
        "          v_b_hat[i] = v_b[i] / denom2\n",
        "\n",
        "        for i in range(len(W)):\n",
        "          weight=W[i]\n",
        "          deriv=dw[i]\n",
        "          W[i] = weight - (eta / np.sqrt(v_w_hat[i] + eps)) * m_w_hat[i] - eta*alpha*weight\n",
        "\n",
        "        for i in range(len(b)):\n",
        "          bias=b[i]\n",
        "          deriv=db[i]\n",
        "          b[i] = bias - (eta / np.sqrt(v_b_hat[i] + eps)) * m_b_hat[i] - eta*alpha*bias\n",
        "        \n",
        "        dw , db = initialize_zeros(784,hl,ol)\n",
        "\n",
        "    val_acc, val_loss,yt_val,ypred_train = get_predictions_accuracy(W, b, valid_x, valid_y, act_fun, loss_fun)\n",
        "    train_acc, train_loss,yt_train,ypred_train = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)\n",
        "    test_acc, test_loss,yt_test,ypred_test = get_predictions_accuracy(W, b, test_x, test_y, act_fun, loss_fun)\n",
        "\n",
        "    print_error_log_wandb(e,train_acc,val_acc,test_acc,train_loss,val_loss,loss_fun)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-lW4pgQIZag"
      },
      "source": [
        "#Confusion_matrix \n",
        "(Implemented in other file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:37.690981Z",
          "iopub.status.busy": "2023-03-17T18:35:37.690619Z",
          "iopub.status.idle": "2023-03-17T18:35:40.728758Z",
          "shell.execute_reply": "2023-03-17T18:35:40.727423Z",
          "shell.execute_reply.started": "2023-03-17T18:35:37.690944Z"
        },
        "id": "0SW5mfI0JWAp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_confusion_matrix(y_true , y_pred , class_names , figsize=(20,20)):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=class_names)\n",
        "    fontsize = 14\n",
        "    r=class_names[::-1]\n",
        "    #z_text = [[str(y_true) for y_true in y_pred] for y_pred in cm]\n",
        "\n",
        "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    h = [ [0 for _ in range(len(class_names))] for _ in range(len(class_names)) ]\n",
        "    #h = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(1,nrows+1):\n",
        "        for j in range(1,ncols+1):\n",
        "            c = cm[i-1, j-1]\n",
        "            p = cm_perc[i-1, j-1]\n",
        "            if i == j:\n",
        "                s = cm_sum[i-1]\n",
        "                annot[i-1, j-1] = '%.1f%% <br> %d/%d' % (p, c, s)\n",
        "                h[i-1][j-1] = '%d %s are correctly classified' % (c,labels[i-1])\n",
        "            elif c == 0:\n",
        "                annot[i-1, j-1] = ''\n",
        "                h[i-1][j-1] = ''\n",
        "            else:\n",
        "                annot[i-1, j-1] = '%.1f%% <br> %d' % (p, c)\n",
        "                h[i-1][j-1] = '%d %s are wrongly classified as %s' % (c,labels[i-1],labels[j-1])\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(cm , x = class_names, y = class_names , text=h,annotation_text = annot , hoverinfo='text' ,colorscale ='blugrn_R')\n",
        "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
        "    \n",
        "   \n",
        "    # add custom xaxis title\n",
        "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),x=0.5,y=-0.15,showarrow=False,text=\"Predicted value\",xref=\"paper\",yref=\"paper\"))\n",
        "\n",
        "    # add custom yaxis title\n",
        "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),x=-0.35,y=0.5,showarrow=False,text=\"Real value\",textangle=-90,xref=\"paper\",yref=\"paper\"))\n",
        "\n",
        "    # adjust margins to make room for yaxis title\n",
        "    fig.update_layout(margin=dict(t=50, l=200))\n",
        "    fig.update_annotations(font_size=14)\n",
        "   \n",
        "    fig['data'][0]['showscale'] = True\n",
        "    fig.update_xaxes(side=\"top\")\n",
        "    fig.show()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myOelQjrNW2f"
      },
      "source": [
        "#Predictions and accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.731245Z",
          "iopub.status.busy": "2023-03-17T18:35:40.730399Z",
          "iopub.status.idle": "2023-03-17T18:35:40.748956Z",
          "shell.execute_reply": "2023-03-17T18:35:40.747764Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.731193Z"
        },
        "id": "ULyXvX_Qr8Sh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predict_sigmoid(a,h,W, b, X, y, method, loss_fun,num_layers):\n",
        "    for i in range(1 , num_layers):\n",
        "        a = np.dot( W[i], h ) + b[i]\n",
        "        h = sigmoid(a)\n",
        "    return a,h\n",
        "\n",
        "def predict_tanh(a,h,W, b, X, y, method, loss_fun,num_layers):\n",
        "    for i in range(1 , num_layers):\n",
        "        a = np.dot( W[i], h ) + b[i]\n",
        "        h = tanh(a)\n",
        "    return a,h\n",
        "\n",
        "def predict_relu(a,h,W, b, X, y, method, loss_fun,num_layers):\n",
        "    for i in range(1 , num_layers):\n",
        "        a = np.dot( W[i], h ) + b[i]\n",
        "        h = relu(a)\n",
        "    return a,h\n",
        "\n",
        "def predict_identity(a,h,W, b, X, y, method, loss_fun,num_layers):\n",
        "    return a,h\n",
        "\n",
        "def get_predictions_accuracy(W, b, X, y, method, loss_fun):\n",
        "  sum,loss=0,0\n",
        "  yhat = []\n",
        "  yt = []\n",
        "  for dp in range(len(X)):\n",
        "    a = []\n",
        "    h = []\n",
        "    h = X[dp] \n",
        "    num_layers = (len(W)-1)\n",
        "\n",
        "    if method=='sigmoid':\n",
        "        a,h = predict_sigmoid(a,h,W, b, X, y, method, loss_fun,num_layers)\n",
        "\n",
        "    elif method=='tanh':\n",
        "        a,h = predict_tanh(a,h,W, b, X, y, method, loss_fun,num_layers)\n",
        "\n",
        "    elif method=='relu':\n",
        "        a,h = predict_relu(a,h,W, b, X, y, method, loss_fun,num_layers)\n",
        "    elif method=='identity':\n",
        "        a,h = predict_relu(a,h,W, b, X, y, method, loss_fun,num_layers)\n",
        "\n",
        "    a = np.dot( W[num_layers], h ) + b[num_layers]\n",
        "    y_pred = softmax(a)\n",
        "\n",
        "    ytrue = y[dp]\n",
        "    if(ytrue[np.argmax(y_pred)]==1):\n",
        "      sum=sum+1\n",
        "    \n",
        "    if loss_fun == \"cross_entropy\":\n",
        "      loss += -np.sum(ytrue*np.log(y_pred))\n",
        "    else:\n",
        "      loss += np.sum((ytrue-y_pred)**2)\n",
        "\n",
        "    yhat.append(labels[np.argmax(y_pred)])\n",
        "    yt.append(labels[np.argmax(ytrue)])\n",
        "\n",
        "  acc=sum/len(X)\n",
        "  loss=loss/len(X)\n",
        "\n",
        "  return acc,loss,yt,yhat\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sweep configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.751347Z",
          "iopub.status.busy": "2023-03-17T18:35:40.750667Z",
          "iopub.status.idle": "2023-03-17T18:35:40.775542Z",
          "shell.execute_reply": "2023-03-17T18:35:40.774385Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.751306Z"
        },
        "id": "lyrZVhaeso1u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "sweep_config_temp={\n",
        "  \"name\": \"Assignment_1\",\n",
        "  \"method\": \"bayes\",\n",
        "  \"metric\": {\n",
        "      \"name\": \"Valid Acc\",\n",
        "      \"goal\": \"maximize\"   \n",
        "    },\n",
        "  \"parameters\": {\n",
        "        \"epochs\": {\n",
        "            \"values\": [ 5, 10]\n",
        "        },\n",
        "        \"hidden_layers\":{\n",
        "            \"values\":[3, 4, 5]\n",
        "        },\n",
        "        \"hidden_layer_size\":{\n",
        "            \"values\":[32, 64, 128]  \n",
        "        },\n",
        "        \"eta\":{\n",
        "            \"values\":[0.001,0.0001]\n",
        "        },\n",
        "        \"optimizer\":{\n",
        "            \"values\":[ 'sgd', 'mgd', 'nag', 'rmsprop', 'adam', 'nadam']\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\": [16, 32, 64]\n",
        "        },\n",
        "        \"alpha\":{\n",
        "            \"values\":[ 0, 0.0005, 0.5]\n",
        "        },\n",
        "        \"strat\":{\n",
        "            \"values\":['xavier','random']\n",
        "        },\n",
        "        \"act_fun\":{\n",
        "            \"values\":[ 'sigmoid', 'tanh','relu']\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.777910Z",
          "iopub.status.busy": "2023-03-17T18:35:40.776853Z",
          "iopub.status.idle": "2023-03-17T18:35:40.789906Z",
          "shell.execute_reply": "2023-03-17T18:35:40.788640Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.777857Z"
        },
        "id": "fiT72DwmvD-c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def helper(W , b , train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun):\n",
        "\n",
        "  test_acc_ce , test_loss_ce , ytrue , ypred = get_predictions_accuracy(W, b, test_x, test_y, config.act_fun, loss_fun[0])\n",
        "\n",
        "  # cmat = get_confusion_matrix(ytrue , ypred , labels , figsize=(20,20))\n",
        "\n",
        "  if len(loss_fun)==1:\n",
        "    wandb.log({\n",
        "        \"test_acc\" : test_acc_ce*100,\n",
        "        \"test_loss\" : test_loss_ce,\n",
        "#         \"Confusion_Matrix\": cmat  \n",
        "        })\n",
        "  else:\n",
        "    W , b = second(train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun[1])\n",
        "    test_acc_sq , test_loss_sq , ytrue_sq , ypred_sq = get_predictions_accuracy(W, b, test_x, test_y, config.act_fun, loss_fun[1])\n",
        "    wandb.log({\n",
        "        \"test_acc\" : test_acc_ce*100,\n",
        "        \"test_loss\" : test_loss_ce,\n",
        "        \"test_acc (squared error)\" : test_acc_sq*100,\n",
        "        \"test_loss (squared error)\" : test_loss_sq,\n",
        "        # \"Confusion_Matrix\": cmat\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_WLZGtLTw0s"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.792522Z",
          "iopub.status.busy": "2023-03-17T18:35:40.791739Z",
          "iopub.status.idle": "2023-03-17T18:35:40.806606Z",
          "shell.execute_reply": "2023-03-17T18:35:40.805354Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.792470Z"
        },
        "id": "4OPrOA_8vED1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def second(train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun):\n",
        "\n",
        "  act_fun = config.act_fun\n",
        "  epochs = config.epochs\n",
        "  strat = config.strat\n",
        "  alpha = config.alpha\n",
        "  eta = config.eta\n",
        "  batch_size = config.batch_size\n",
        "  optimizer = config.optimizer\n",
        "\n",
        "  if optimizer == 'sgd':\n",
        "    W , b = stochastic_gradient_descent( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "\n",
        "  elif optimizer == 'rmsprop':\n",
        "    W , b = rmsprop( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "\n",
        "  elif optimizer == 'mgd':\n",
        "    W , b = momentum_gradient_descent( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "  \n",
        "  elif optimizer == 'nag':\n",
        "    W , b = nesterov_gradient_descent( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "  \n",
        "  elif optimizer == 'adam':\n",
        "    W , b = adaptive_moments( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "\n",
        "  elif optimizer == 'nadam':\n",
        "    W , b = nadam( train_x , train_y , valid_x , valid_y , d , hl , ol , act_fun , loss_fun , epochs , eta , strat , alpha , batch_size)\n",
        "\n",
        "  return W,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdlm_S-Q0iO1"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.808566Z",
          "iopub.status.busy": "2023-03-17T18:35:40.808158Z",
          "iopub.status.idle": "2023-03-17T18:35:40.820258Z",
          "shell.execute_reply": "2023-03-17T18:35:40.819174Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.808531Z"
        },
        "id": "ceIkf_3u0g95",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  run=wandb.init()\n",
        "  config = wandb.config\n",
        "\n",
        "  loss_fun=[\"cross_entropy\"]\n",
        "\n",
        "  hl = [config.hidden_layer_size]*config.hidden_layers\n",
        "  ol = [len(train_y[0])]\n",
        "\n",
        "  name = \"hl_\" + str(config.hidden_layers) + \"_bs_\" + str(config.batch_size) + \"_ac_\" + config.act_fun\n",
        "  run.name = name\n",
        "\n",
        "  W,b = second(train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun[0])\n",
        "  helper(W , b , train_x , train_y , valid_x , valid_y , d ,hl , ol , config , loss_fun)\n",
        "  \n",
        "  #Showing one image of each class (Question - 1)\n",
        "  \n",
        "  run.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DaYRj2Y42H5B"
      },
      "source": [
        "# For running sweep in Wandb "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:40.823251Z",
          "iopub.status.busy": "2023-03-17T18:35:40.822286Z",
          "iopub.status.idle": "2023-03-17T18:35:41.138894Z",
          "shell.execute_reply": "2023-03-17T18:35:41.137549Z",
          "shell.execute_reply.started": "2023-03-17T18:35:40.823199Z"
        },
        "id": "GQodczbf1r6v",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# sweep_id = wandb.sweep(sweep_config_temp, entity=\"cs22m035\", project=\"Assignment_1\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logging in Question 1 in Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "execution": {
          "iopub.execute_input": "2023-03-17T18:35:41.140690Z",
          "iopub.status.busy": "2023-03-17T18:35:41.140354Z"
        },
        "id": "Wtd2Z3fZ1r91",
        "outputId": "7d1c8227-ed45-478b-8fab-582dc2fd005e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_142107-uxeautbb</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m035/Assignment_1/runs/uxeautbb' target=\"_blank\">cerulean-frog-681</a></strong> to <a href='https://wandb.ai/cs22m035/Assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m035/Assignment_1' target=\"_blank\">https://wandb.ai/cs22m035/Assignment_1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m035/Assignment_1/runs/uxeautbb' target=\"_blank\">https://wandb.ai/cs22m035/Assignment_1/runs/uxeautbb</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.init(entity=\"cs22m035\", project=\"Assignment_1\")\n",
        "# wandb.run.name = \"Q1\"\n",
        "show_images(train_images , train_labels , labels)\n",
        "# wandb.agent(sweep_id, train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ploting Confusion Matrix for best configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eoT3bGm8I46Z",
        "outputId": "cdaa8977-10b8-4c26-bf35-b2445a403850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 2  cross_entropy  train_acc : 0.8830370370370371 valid_acc : 0.8765 test_acc : 0.861\n",
            "epoch: 3  cross_entropy  train_acc : 0.895425925925926 valid_acc : 0.883 test_acc : 0.8679\n",
            "epoch: 4  cross_entropy  train_acc : 0.9019259259259259 valid_acc : 0.8845 test_acc : 0.8713\n",
            "epoch: 5  cross_entropy  train_acc : 0.9081111111111111 valid_acc : 0.888 test_acc : 0.8764\n",
            "epoch: 6  cross_entropy  train_acc : 0.91 valid_acc : 0.8868333333333334 test_acc : 0.8749\n",
            "epoch: 7  cross_entropy  train_acc : 0.9125 valid_acc : 0.8871666666666667 test_acc : 0.8733\n",
            "epoch: 8  cross_entropy  train_acc : 0.9152592592592592 valid_acc : 0.8836666666666667 test_acc : 0.8731\n",
            "epoch: 9  cross_entropy  train_acc : 0.9235740740740741 valid_acc : 0.8885 test_acc : 0.8781\n",
            "epoch: 10  cross_entropy  train_acc : 0.9169074074074074 valid_acc : 0.876 test_acc : 0.8675\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:uxeautbb) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td></td></tr><tr><td>Train Acc</td><td></td></tr><tr><td>Train Loss</td><td></td></tr><tr><td>Valid Acc</td><td></td></tr><tr><td>Valid Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Acc</td><td>91.69074</td></tr><tr><td>Train Loss</td><td>0.22367</td></tr><tr><td>Valid Acc</td><td>87.6</td></tr><tr><td>Valid Loss</td><td>0.37771</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cerulean-frog-681</strong> at: <a href='https://wandb.ai/cs22m035/Assignment_1/runs/uxeautbb' target=\"_blank\">https://wandb.ai/cs22m035/Assignment_1/runs/uxeautbb</a><br/>Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230319_142107-uxeautbb/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:uxeautbb). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_150300-5kch5zum</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m035/confusion/runs/5kch5zum' target=\"_blank\">comic-plant-7</a></strong> to <a href='https://wandb.ai/cs22m035/confusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m035/confusion' target=\"_blank\">https://wandb.ai/cs22m035/confusion</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m035/confusion/runs/5kch5zum' target=\"_blank\">https://wandb.ai/cs22m035/confusion/runs/5kch5zum</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d77db4d7-d461-43f2-8063-808171e3efb4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d77db4d7-d461-43f2-8063-808171e3efb4\")) {                    Plotly.newPlot(                        \"d77db4d7-d461-43f2-8063-808171e3efb4\",                        [{\"colorscale\":[[0.0,\"rgb(29, 79, 96)\"],[0.16666666666666666,\"rgb(38, 107, 110)\"],[0.3333333333333333,\"rgb(54, 135, 122)\"],[0.5,\"rgb(77, 162, 132)\"],[0.6666666666666666,\"rgb(109, 188, 144)\"],[0.8333333333333334,\"rgb(150, 210, 164)\"],[1.0,\"rgb(196, 230, 195)\"]],\"hoverinfo\":\"text\",\"reversescale\":false,\"showscale\":true,\"text\":[[\"4686 T-shirt/Top are correctly classified\",\"20 T-shirt/Top are wrongly classified as Trouser\",\"73 T-shirt/Top are wrongly classified as Pullover\",\"184 T-shirt/Top are wrongly classified as Dress\",\"25 T-shirt/Top are wrongly classified as Coat\",\"4 T-shirt/Top are wrongly classified as Sandal\",\"386 T-shirt/Top are wrongly classified as Shirt\",\"\",\"22 T-shirt/Top are wrongly classified as Bag\",\"\"],[\"\",\"5359 Trouser are correctly classified\",\"2 Trouser are wrongly classified as Pullover\",\"30 Trouser are wrongly classified as Dress\",\"4 Trouser are wrongly classified as Coat\",\"1 Trouser are wrongly classified as Sandal\",\"1 Trouser are wrongly classified as Shirt\",\"\",\"3 Trouser are wrongly classified as Bag\",\"\"],[\"25 Pullover are wrongly classified as T-shirt/Top\",\"2 Pullover are wrongly classified as Trouser\",\"4884 Pullover are correctly classified\",\"31 Pullover are wrongly classified as Dress\",\"197 Pullover are wrongly classified as Coat\",\"\",\"258 Pullover are wrongly classified as Shirt\",\"\",\"3 Pullover are wrongly classified as Bag\",\"\"],[\"20 Dress are wrongly classified as T-shirt/Top\",\"99 Dress are wrongly classified as Trouser\",\"23 Dress are wrongly classified as Pullover\",\"4967 Dress are correctly classified\",\"253 Dress are wrongly classified as Coat\",\"\",\"30 Dress are wrongly classified as Shirt\",\"3 Dress are wrongly classified as Sneaker\",\"5 Dress are wrongly classified as Bag\",\"\"],[\"1 Coat are wrongly classified as T-shirt/Top\",\"3 Coat are wrongly classified as Trouser\",\"591 Coat are wrongly classified as Pullover\",\"60 Coat are wrongly classified as Dress\",\"4516 Coat are correctly classified\",\"1 Coat are wrongly classified as Sandal\",\"208 Coat are wrongly classified as Shirt\",\"\",\"18 Coat are wrongly classified as Bag\",\"2 Coat are wrongly classified as Ankle Boot\"],[\"\",\"\",\"\",\"\",\"\",\"5115 Sandal are correctly classified\",\"\",\"151 Sandal are wrongly classified as Sneaker\",\"4 Sandal are wrongly classified as Bag\",\"130 Sandal are wrongly classified as Ankle Boot\"],[\"425 Shirt are wrongly classified as T-shirt/Top\",\"7 Shirt are wrongly classified as Trouser\",\"371 Shirt are wrongly classified as Pullover\",\"130 Shirt are wrongly classified as Dress\",\"196 Shirt are wrongly classified as Coat\",\"\",\"4246 Shirt are correctly classified\",\"2 Shirt are wrongly classified as Sneaker\",\"23 Shirt are wrongly classified as Bag\",\"\"],[\"\",\"\",\"\",\"\",\"\",\"5 Sneaker are wrongly classified as Sandal\",\"\",\"5015 Sneaker are correctly classified\",\"1 Sneaker are wrongly classified as Bag\",\"379 Sneaker are wrongly classified as Ankle Boot\"],[\"\",\"1 Bag are wrongly classified as Trouser\",\"2 Bag are wrongly classified as Pullover\",\"3 Bag are wrongly classified as Dress\",\"4 Bag are wrongly classified as Coat\",\"\",\"2 Bag are wrongly classified as Shirt\",\"7 Bag are wrongly classified as Sneaker\",\"5381 Bag are correctly classified\",\"\"],[\"\",\"\",\"\",\"\",\"\",\"3 Ankle Boot are wrongly classified as Sandal\",\"\",\"52 Ankle Boot are wrongly classified as Sneaker\",\"1 Ankle Boot are wrongly classified as Bag\",\"5344 Ankle Boot are correctly classified\"]],\"x\":[\"T-shirt/Top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"],\"y\":[\"T-shirt/Top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"],\"z\":[[4686,20,73,184,25,4,386,0,22,0],[0,5359,2,30,4,1,1,0,3,0],[25,2,4884,31,197,0,258,0,3,0],[20,99,23,4967,253,0,30,3,5,0],[1,3,591,60,4516,1,208,0,18,2],[0,0,0,0,0,5115,0,151,4,130],[425,7,371,130,196,0,4246,2,23,0],[0,0,0,0,0,5,0,5015,1,379],[0,1,2,3,4,0,2,7,5381,0],[0,0,0,0,0,3,0,52,1,5344]],\"type\":\"heatmap\"}],                        {\"annotations\":[{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"86.8% <br> 4686/5400\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 20\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"1.4% <br> 73\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"3.4% <br> 184\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.5% <br> 25\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 4\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"7.1% <br> 386\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 22\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"T-shirt/Top\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"99.2% <br> 5359/5400\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.6% <br> 30\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 4\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Trouser\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.5% <br> 25\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"90.4% <br> 4884/5400\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.6% <br> 31\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"3.6% <br> 197\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"4.8% <br> 258\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Pullover\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 20\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"1.8% <br> 99\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 23\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"92.0% <br> 4967/5400\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"4.7% <br> 253\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.6% <br> 30\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 5\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Dress\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"10.9% <br> 591\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"1.1% <br> 60\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"83.6% <br> 4516/5400\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"3.9% <br> 208\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.3% <br> 18\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Coat\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"94.7% <br> 5115/5400\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"2.8% <br> 151\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 4\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"2.4% <br> 130\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Sandal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"7.9% <br> 425\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 7\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"6.9% <br> 371\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"2.4% <br> 130\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"3.6% <br> 196\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"78.6% <br> 4246/5400\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.4% <br> 23\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Shirt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 5\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"92.9% <br> 5015/5400\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"7.0% <br> 379\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Sneaker\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 4\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 2\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 7\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"99.6% <br> 5381/5400\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Bag\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"T-shirt/Top\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Trouser\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Pullover\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Dress\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Coat\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.1% <br> 3\",\"x\":\"Sandal\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"\",\"x\":\"Shirt\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"1.0% <br> 52\",\"x\":\"Sneaker\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\",\"size\":14},\"showarrow\":false,\"text\":\"0.0% <br> 1\",\"x\":\"Bag\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\",\"size\":14},\"showarrow\":false,\"text\":\"99.0% <br> 5344/5400\",\"x\":\"Ankle Boot\",\"xref\":\"x\",\"y\":\"Ankle Boot\",\"yref\":\"y\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Predicted value\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.15,\"yref\":\"paper\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Real value\",\"textangle\":-90,\"x\":-0.35,\"xref\":\"paper\",\"y\":0.5,\"yref\":\"paper\"}],\"xaxis\":{\"dtick\":1,\"gridcolor\":\"rgb(0, 0, 0)\",\"side\":\"top\",\"ticks\":\"\"},\"yaxis\":{\"dtick\":1,\"ticks\":\"\",\"ticksuffix\":\"  \",\"autorange\":\"reversed\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"margin\":{\"t\":50,\"l\":200}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d77db4d7-d461-43f2-8063-808171e3efb4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optimizer=nadam\n",
        "epochs=10\n",
        "batch = 64\n",
        "eta=0.001\n",
        "alpha=0\n",
        "hidden_layer_size = 128\n",
        "hidden_layers = 5\n",
        "strat='xavier'\n",
        "act_fun ='relu'\n",
        "loss_fun='cross_entropy'\n",
        "hl = [hidden_layer_size]*hidden_layers\n",
        "ol = [len(train_y[0])]\n",
        "n_hl = len(hl)\n",
        "\n",
        "if optimizer==stochastic_gradient_descent:\n",
        "  W,b = stochastic_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==momentum_gradient_descent:\n",
        "  W,b = momentum_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==nesterov_gradient_descent:\n",
        "  W,b = nesterov_gradient_descent(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==rmsprop:\n",
        "  W,b = rmsprop(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==adaptive_moments:\n",
        "  W,b = adaptive_moments(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        "elif optimizer==nadam:\n",
        "  W,b = nadam(train_x,train_y,valid_x,valid_y,d,hl,ol,act_fun,loss_fun,epochs,eta,strat,alpha,batch)\n",
        "\n",
        " \n",
        "wandb.init(entity=\"cs22m035\", project=\"confusion\")\n",
        "# wandb.run.name = \"Q1\"\n",
        "# show_images(train_images , train_labels , labels)\n",
        "\n",
        "train_acc, train_loss,ytrue,ypred = get_predictions_accuracy(W, b, train_x, train_y, act_fun, loss_fun)  \n",
        "cmat = get_confusion_matrix(ytrue , ypred , labels , figsize=(20,20))\n",
        "\n",
        "wandb.log({\n",
        "          \"Confusion_Matrix\": cmat  \n",
        "        })"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
